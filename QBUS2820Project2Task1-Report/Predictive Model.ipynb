{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Clothing_Store.csv')\n",
    "\n",
    "dummies = pd.get_dummies(data[['VALPHON']],  drop_first=True)\n",
    "data=data.join(dummies)\n",
    "\n",
    "del data['VALPHON']\n",
    "final_train = data.sample(frac=0.6, random_state=450411920)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "#Now we have final train/test which only has predictors whilst y_train/test are the response\n",
    "y_train = final_train.pop('RESP')\n",
    "y_test = final_test.pop('RESP')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to try out some models here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more information about the models I use in this: http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to store the results from our models\n",
    "pred = []\n",
    "method = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(final_train,y_train)\n",
    "predneigh = neigh.predict(final_test)\n",
    "pred.append(predneigh)\n",
    "method.append('KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adaptive Boosting\n",
    "regr = AdaBoostClassifier(learning_rate = 1, n_estimators = 350)\n",
    "model.append(regr)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "pred.append(adapred)\n",
    "method.append('AdaptiveBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quadratic Discriminant analysis\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "QDA.fit(final_train, y_train)\n",
    "predQDA = QDA.predict(final_test)\n",
    "pred.append(predQDA)\n",
    "method.append('QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear Discriminant analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(final_train, y_train)\n",
    "predLDA = LDA.predict(final_test)\n",
    "pred.append(predLDA)\n",
    "method.append('LDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "DT = DecisionTreeClassifier(random_state=0)\n",
    "DT.fit(final_train,y_train)\n",
    "predDT = DT.predict(final_test)\n",
    "pred.append(predDT)\n",
    "method.append('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "RandomFor = RandomForestClassifier(max_depth=None,min_samples_split=2)\n",
    "model.append(RandomFor)\n",
    "RandomFor = RandomFor.fit(final_train,y_train)\n",
    "randomforpred = RandomFor.predict(final_test)\n",
    "pred.append(randomforpred)\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random Forest\n",
    "Extratree = ExtraTreesClassifier(max_depth=None,min_samples_split=2)\n",
    "model.append(Extratree)\n",
    "Extratree = Extratree.fit(final_train,y_train)\n",
    "predFinalExtRandomForest = Extratree.predict(final_test)\n",
    "pred.append(predFinalExtRandomForest)\n",
    "method.append('Extreme Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "GradBoost = GradientBoostingClassifier(n_estimators=350, learning_rate=0.1,\n",
    "                                 max_depth=1, random_state=0)\n",
    "model.append(GradBoost)\n",
    "GradBoost = GradBoost.fit(final_train,y_train)\n",
    "predGradBoost = GradBoost.predict(final_test)\n",
    "pred.append(predGradBoost)\n",
    "method.append('Gradient Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "NaiveB = GaussianNB()\n",
    "model.append(NaiveB)\n",
    "NaiveB = NaiveB.fit(final_train, y_train)\n",
    "predNaiveB = NaiveB.predict(final_test)\n",
    "pred.append(predNaiveB)\n",
    "method.append('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "LogReg = LogisticRegression(random_state=450411920)\n",
    "model.append(LogReg)\n",
    "LogReg = LogReg.fit(final_train,y_train)\n",
    "predLogReg = LogReg.predict(final_test)\n",
    "pred.append(predLogReg)\n",
    "method.append('Logit Reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate how each of our model performs from a confusion matrix.\n",
    "https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates us a table for results\n",
    "def getResultTable(rows, predictions):\n",
    "    columns=['Accuracy for Yes', 'Accuracy for No', 'Overall Accuracy']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    \n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        results.iloc[row,0] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,1] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,2] = (accuracy_score(y_test, pred))\n",
    "        \n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaptiveBoost</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extreme Random Forest</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logit Reg</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy for Yes  Accuracy for No  Overall Accuracy\n",
       "KNN                               0.836            0.200             0.789\n",
       "AdaptiveBoost                     0.876            0.594             0.850\n",
       "QDA                               0.902            0.391             0.782\n",
       "LDA                               0.868            0.606             0.849\n",
       "Decision Tree                     0.876            0.381             0.794\n",
       "Random Forest                     0.864            0.580             0.844\n",
       "Extreme Random Forest             0.860            0.576             0.843\n",
       "Gradient Boost                    0.871            0.655             0.855\n",
       "Naive Bayes                       0.834            0.224             0.830\n",
       "Logit Reg                         0.833              NaN             0.833"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix is:\n",
      "[[6738  509]\n",
      " [1322  127]]\n",
      "Accuracy of predicting Yes is 0.836\n",
      "Accuracy of predicting No is 0.200\n",
      "Overall accuracy is 0.789\n",
      "\n",
      "AdaptiveBoost confusion matrix is:\n",
      "[[6928  319]\n",
      " [ 982  467]]\n",
      "Accuracy of predicting Yes is 0.876\n",
      "Accuracy of predicting No is 0.594\n",
      "Overall accuracy is 0.850\n",
      "\n",
      "QDA confusion matrix is:\n",
      "[[6007 1240]\n",
      " [ 653  796]]\n",
      "Accuracy of predicting Yes is 0.902\n",
      "Accuracy of predicting No is 0.391\n",
      "Overall accuracy is 0.782\n",
      "\n",
      "LDA confusion matrix is:\n",
      "[[6995  252]\n",
      " [1062  387]]\n",
      "Accuracy of predicting Yes is 0.868\n",
      "Accuracy of predicting No is 0.606\n",
      "Overall accuracy is 0.849\n",
      "\n",
      "Decision Tree confusion matrix is:\n",
      "[[6360  887]\n",
      " [ 902  547]]\n",
      "Accuracy of predicting Yes is 0.876\n",
      "Accuracy of predicting No is 0.381\n",
      "Overall accuracy is 0.794\n",
      "\n",
      "Random Forest confusion matrix is:\n",
      "[[6996  251]\n",
      " [1103  346]]\n",
      "Accuracy of predicting Yes is 0.864\n",
      "Accuracy of predicting No is 0.580\n",
      "Overall accuracy is 0.844\n",
      "\n",
      "Extreme Random Forest confusion matrix is:\n",
      "[[7023  224]\n",
      " [1145  304]]\n",
      "Accuracy of predicting Yes is 0.860\n",
      "Accuracy of predicting No is 0.576\n",
      "Overall accuracy is 0.843\n",
      "\n",
      "Gradient Boost confusion matrix is:\n",
      "[[7034  213]\n",
      " [1045  404]]\n",
      "Accuracy of predicting Yes is 0.871\n",
      "Accuracy of predicting No is 0.655\n",
      "Overall accuracy is 0.855\n",
      "\n",
      "Naive Bayes confusion matrix is:\n",
      "[[7202   45]\n",
      " [1436   13]]\n",
      "Accuracy of predicting Yes is 0.834\n",
      "Accuracy of predicting No is 0.224\n",
      "Overall accuracy is 0.830\n",
      "\n",
      "Logit Reg confusion matrix is:\n",
      "[[7247    0]\n",
      " [1449    0]]\n",
      "Accuracy of predicting Yes is 0.833\n",
      "Accuracy of predicting No is nan\n",
      "Overall accuracy is 0.833\n",
      "\n",
      "Best model is Gradient Boost\n",
      "Accuracy of the model is 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#If we want to actually see a confusion matrix\n",
    "maxscore = 0\n",
    "bestmodel = 'none'\n",
    "for prediction, name in zip(pred,method):\n",
    "    print('{} confusion matrix is:'.format(name))\n",
    "    matrix = confusion_matrix(y_test, prediction)\n",
    "    print(matrix)\n",
    "    print('Accuracy of predicting Yes is %.3f'%(matrix[0][0]/(matrix[0][0]+matrix[1][0])))\n",
    "    print('Accuracy of predicting No is %.3f'%(matrix[1][1]/(matrix[0][1]+matrix[1][1])))\n",
    "    print('Overall accuracy is %.3f' % (accuracy_score(y_test, prediction)))\n",
    "    print('')\n",
    "    if (accuracy_score(y_test,prediction)>maxscore):\n",
    "        maxscore = accuracy_score(y_test,prediction)\n",
    "        bestmodel = name\n",
    "\n",
    "print('Best model is {}'.format(bestmodel))\n",
    "print('Accuracy of the model is %.3f' %(maxscore))\n",
    "    #8696 is total observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Gradient Boosting was the most accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret a confusion matrix, the column 1 and 2 represent the model predicting Yes or No. Then the rows represent were they actually yes or no. The [0,0] entry means that we predicted that many to be Yes, and it turns out that we were correct in predicting those, so that tells us how many yes observations we predicted correctly. Likewise, the [1,1] entry means how many no's we predicted correctly. The bottom left, [1,0] entry means we predicted yes, but was actually no and [0,1] entry is the vice versa. Conclusively, the diagonals of the matrix tells us how accurate are our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to tune the hyperparameter in our models, we use this package called randomizedsearchcv.\n",
    "\n",
    "This allows us to try out different hyperparameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "modelname = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with KNN with inspiration from:\n",
    "\n",
    "http://www.ritchieng.com/machine-learning-efficiently-search-tuning-param/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try setting from 1 - 25 neighbors\n",
    "k_range = range(1, 25)\n",
    "\n",
    "# we create a list. This allows us to see whether we should weigh all neighbours equally or weigh closer ones more\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the objects necessary for us to try cross-validation in order to locate best hyperparameters\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "knnopt = rand.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.834\n",
      "{'weights': 'uniform', 'n_neighbors': 22}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=22, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%rand.best_score_)\n",
    "print(rand.best_params_)\n",
    "print(rand.best_estimator_)\n",
    "models.append(knnopt)\n",
    "modelname.append('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for KNN involves 22 neighbours and having uniform neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7391884083841449, 0.8200690066610925, 0.79262347447833981, 0.82489923806123699, 0.81171339922396868, 0.82804305752590679, 0.82152594443765903, 0.83011278760604679, 0.82712304700344796, 0.83271991469292261, 0.83179966929414972, 0.83317968507783802, 0.83218322231512887, 0.83387010400323169, 0.83325660707071647, 0.83387010400323192, 0.83302666315918028, 0.83394690855795339, 0.83379365176298159, 0.83394690855795317, 0.83387033887954587, 0.83402359567451767, 0.83402359567451767, 0.83417673503133238]\n"
     ]
    }
   ],
   "source": [
    "#Now constructing a graph for this\n",
    "k_range = range(1, 25)\n",
    "\n",
    "# list of scores from k_range\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'uniform')\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, final_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x120af7c88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bfe0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Neighbours vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that increasing number of neighbours improves accuracy. However, we need to be wary of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "treeopt = tree_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.849\n",
      "{'min_samples_leaf': 1, 'max_features': 8, 'max_depth': 3, 'criterion': 'entropy'}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%tree_cv.best_score_)\n",
    "print(tree_cv.best_params_)\n",
    "print(tree_cv.best_estimator_)\n",
    "models.append(treeopt)\n",
    "modelname.append('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision tree, we should set min sample leaves to 5, have a maximum of 8 features, a max depth of 3, and using the gini criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8467504861939702, 0.84682529430002162, 0.84866566765941054, 0.85042864927329265, 0.84966342224184732, 0.84299223029152837, 0.84261102603369076, 0.84184192354306209]\n"
     ]
    }
   ],
   "source": [
    "#Now constructing a graph for this\n",
    "tree_range = range(2, 10)\n",
    "\n",
    "# list of scores from t_range\n",
    "t_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in tree_range:\n",
    "    # 2. run Decision tree with different value for depth of tree\n",
    "    tree = DecisionTreeClassifier(max_depth = k, criterion='gini', max_features = 8, max_leaf_nodes = None )\n",
    "    # 3. obtain cross_val_score for Decision tree with depth of k\n",
    "    scores = cross_val_score(tree, final_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for decision tree to t_scores list\n",
    "    t_scores.append(scores.mean())\n",
    "print(t_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x115618b38>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bfeba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of Depth for Decision Tree(x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of Depth for Decision Tree')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Depth vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(5,15),\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_split\": range(2,5),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              }\n",
    "\n",
    "# Instantiate a Extremely Random Forest classifier: randext\n",
    "randFor = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randFor_cv\n",
    "randFor_cv = RandomizedSearchCV(randFor,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optrand = randFor_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.853\n",
      "{'n_estimators': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 8, 'max_depth': 3}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randFor_cv.best_score_)\n",
    "print(randFor_cv.best_params_)\n",
    "print(randFor_cv.best_estimator_)\n",
    "models.append(optrand)\n",
    "modelname.append('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:\n",
    "\n",
    "n_estimators: 10\n",
    "\n",
    "maximum features: 8\n",
    "\n",
    "min_samples_split: 2\n",
    "\n",
    "min_samples_leaf: 8\n",
    "\n",
    "No maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(5,15),\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_split\": range(2,5),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              }\n",
    "\n",
    "# Instantiate a Extremely Random Forest classifier: randext\n",
    "randExt = ExtraTreesClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randext_cv\n",
    "randExt_cv = RandomizedSearchCV(randExt,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optext = randExt_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.850\n",
      "{'n_estimators': 11, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 5, 'max_depth': None}\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=5, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=6, min_samples_split=3,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randExt_cv.best_score_)\n",
    "print(randExt_cv.best_params_)\n",
    "print(randExt_cv.best_estimator_)\n",
    "models.append(optext)\n",
    "modelname.append('Extremely Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 11, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 5, 'max_depth': None} tells us the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(330,400,10),\n",
    "              \"learning_rate\": range(1,5),\n",
    "              }\n",
    "\n",
    "# Instantiate a Adaptie boosting classifier: tree\n",
    "randAda = AdaBoostClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randada_cv\n",
    "randAda_cv = RandomizedSearchCV(randAda,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optada = randAda_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.852\n",
      "{'n_estimators': 350, 'learning_rate': 1}\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=350, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randAda_cv.best_score_)\n",
    "print(randAda_cv.best_params_)\n",
    "print(randAda_cv.best_estimator_)\n",
    "models.append(optada)\n",
    "modelname.append('Adaptive Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"loss\": [\"deviance\", \"exponential\"],\n",
    "              \"n_estimators\": range(250,550,50),\n",
    "              \"learning_rate\": [0.1],\n",
    "              \"min_samples_split\" : [2,4],\n",
    "              \"min_samples_leaf\" : range(1,3)\n",
    "              }\n",
    "\n",
    "# Instantiate a GB boosting classifier: randGB\n",
    "randGB = GradientBoostingClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randGB_cv\n",
    "randGB_cv = RandomizedSearchCV(randGB,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optgb = randGB_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.856\n",
      "{'n_estimators': 250, 'min_samples_split': 4, 'min_samples_leaf': 2, 'loss': 'exponential', 'learning_rate': 0.1}\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=2, min_samples_split=4,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randGB_cv.best_score_)\n",
    "print(randGB_cv.best_params_)\n",
    "print(randGB_cv.best_estimator_)\n",
    "models.append(optgb)\n",
    "modelname.append('Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same interpretation as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have finalised tuning our hyperparameters and therefore we can retrain our models to see final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "LogReg = LogisticRegression()\n",
    "optlog = LogReg.fit(final_train,y_train)\n",
    "models.append(optlog)\n",
    "modelname.append('Logit')\n",
    "\n",
    "#Naive Bayes\n",
    "NaiveB = GaussianNB()\n",
    "optnb = NaiveB.fit(final_train,y_train)\n",
    "models.append(optnb)\n",
    "modelname.append('Naive Bayes')\n",
    "\n",
    "#Linear Discriminant analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "optlda = LDA.fit(final_train,y_train)\n",
    "models.append(optlda)\n",
    "modelname.append('LDA')\n",
    "\n",
    "#Quadratic Discriminant analysis\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "optqda = QDA.fit(final_train,y_train)\n",
    "models.append(optqda)\n",
    "modelname.append('QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates us a table for results with hyperparameter optimised models\n",
    "def getResultTable2(rows, modelsUsed):\n",
    "    columns=['Accuracy for Yes', 'Accuracy for No', 'Overall Accuracy']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    predictions = []\n",
    "    for clf in modelsUsed:\n",
    "        pred = clf.predict(final_test)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        results.iloc[row,0] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,1] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,2] = (accuracy_score(y_test, pred))\n",
    "        \n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Random Forest</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaptive Boosting</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy for Yes  Accuracy for No  Overall Accuracy\n",
       "KNN                                 0.833              NaN             0.833\n",
       "Decision Tree                       0.846            0.686             0.842\n",
       "Random Forest                       0.859            0.676             0.850\n",
       "Extremely Random Forest             0.861            0.649             0.850\n",
       "Adaptive Boosting                   0.876            0.594             0.850\n",
       "Gradient Boosting                   0.873            0.647             0.856\n",
       "Logit                               0.833              NaN             0.833\n",
       "Naive Bayes                         0.834            0.224             0.830\n",
       "LDA                                 0.868            0.606             0.849\n",
       "QDA                                 0.902            0.391             0.782"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Warning, this takes a while to run!\n",
    "getResultTable2(modelname, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now combine our models in order to create even better models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have predictions from our models and we can take a majority vote to predict each observation. Here, we use a majority vote. Here, we assign each model as having a vote that is of equal importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemmodels = []\n",
    "ensempredictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we take the 3 and 4 best models to create our model with hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem = VotingClassifier(estimators=[('Adaptive', optada), ('DecisionTree', treeopt), ('GradientBoost', optgb)], voting='hard')\n",
    "ensemmodels.append('Adaboost DecisionTree GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensem1 = ensem.fit(final_train,y_train)\n",
    "ensempred1 = ensem1.predict(final_test)\n",
    "ensempredictions.append(ensempred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem2 = VotingClassifier(estimators=[('Adaptive', optada), ('DecisionTree', treeopt), ('GradientBoost', optgb), ('LDA', optlda)], voting='hard')\n",
    "ensemmodels.append('Adaboost DecisionTree GradientBoost LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem2 = ensem2.fit(final_train,y_train)\n",
    "ensempred2 = ensem2.predict(final_test)\n",
    "ensempredictions.append(ensempred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adaboost DecisionTree GradientBoost</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost DecisionTree GradientBoost LDA</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Accuracy for Yes  Accuracy for No  \\\n",
       "Adaboost DecisionTree GradientBoost                 0.871            0.655   \n",
       "Adaboost DecisionTree GradientBoost LDA             0.860            0.694   \n",
       "\n",
       "                                         Overall Accuracy  \n",
       "Adaboost DecisionTree GradientBoost                 0.856  \n",
       "Adaboost DecisionTree GradientBoost LDA             0.852  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(ensemmodels,ensempredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the best ensemble model and then try soft voting. Here, each base model gets a different weight\n",
    "in their vote. We can use gridsearch CV to find optimal level of weighting for each model.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalensem = VotingClassifier(estimators=[('LDA', optada), ('ExtraTrees', Extratree), ('GradientBoost', GradBoost)], voting='soft', weights = [1,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LDA', RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distribution...         presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[1, 1, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalensem.fit(final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalresults = finalensem.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855450781969\n"
     ]
    }
   ],
   "source": [
    "#Final results\n",
    "print(accuracy_score(y_test, finalresults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like hardvoting with Adaptive boosting, decision trees, and gradient boosting performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
