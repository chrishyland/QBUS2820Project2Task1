{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Clothing_Store.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 predictors for 21740 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by: http://www.comp.dit.ie/btierney/Oracle11gDoc/datamine.111/b28129/classify.htm\n",
    "\n",
    "Here, it costs \\$2.5 to send direct mail marketing to a customer. So a false positive will mean a loss of $2.5 since we send mail for no reason (cite a random source to quote this price).\n",
    "\n",
    "Cost/Benefit values (express in terms of cost):\n",
    "\n",
    "True Negative: 0 since we don't send anything to a customer who would have bought something otherwise.\n",
    "\n",
    "True Positive: -14 + 2.5 = -11.5 (profit is negative cost. Thus, we have profit and cost to send mail)\n",
    "\n",
    "False Negative: 14 (Lost profit and therefore don't make money).\n",
    "\n",
    "False Positive: 2.5\n",
    "\n",
    "Talk and elaborate more about TN, TP, FN, and FP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean amount of money spent by typical customer is \\$114 whilst median was \\$92. Due to data being positively skewed (mean greater than median), we decide to take the average amount spent by a customer was \\$92. We assume profit is 15% of this, so profit made for each successful customer who is sent mail and responds, is \\$14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean amount spent by customer 113.89\n",
      "Median amount spent by customer 92.07\n",
      "Skewness of the amount spent by customer is 3.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean amount spent by customer %.2f\"%data['AVRG'].mean())\n",
    "print(\"Median amount spent by customer %.2f\"%data['AVRG'].median())\n",
    "print(\"Skewness of the amount spent by customer is %.2f\"%data['AVRG'].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21740.000000\n",
       "mean       113.889105\n",
       "std         87.249794\n",
       "min          0.490000\n",
       "25%         60.990000\n",
       "50%         92.070000\n",
       "75%        139.505000\n",
       "max       1919.880000\n",
       "Name: AVRG, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AVRG'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about whether False Negatives or False positives are worse. Seems like false negatives for me since if you send mail to someone who won't respond, you only lose 2 dollars (false positive) whilst if you fail to send it to someone who will respond, you lose \\$14.0 (false negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding/Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "#Compute how many people in dataset responded to marketing campain. RESP means whether they responded or not.\n",
    "print(\"%.2f\"%(data['RESP'].sum()/data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue here since in dataset, only 17% of observations actually responded to marketing campain. We have a MASSIVE class imbalance here. It will be difficult to obtain a good score for the sensitivity as a result.\n",
    "\n",
    "Let's explore more about this dataset and see if any patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a cluster variable which tells us what kind of customer (segment) they are from. Each type is associated with a number from the Microvision Market Segmentation System: http://www.tetrad.com/pub/prices/microvision.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127c6cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clust_type_count = data['CLUSTYPE'].value_counts()\n",
    "ax = sb.barplot(x =clust_type_count.index[:10], y= clust_type_count[:10])\n",
    "ax.set(xlabel='Cluster Type', ylabel='Count', title=\"Most prevalent customer clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, cluster 10 (home sweet home) is the most prevalent life style cluster in our data set. These are families with medium-high income. Analyse what the top 3-5 lifestyles are according to the microvision pdf. Appears customer tends to be rich families that are hihgly educated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE COPY AND PASTE THE CODE FOR THE FEATURE ENGINEERING/EDA TASK THAT YOU'VE DONE OVER HERE (ONLY THE ONES YOU FIND RELEVANT AND WORTH TALKING ABOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since you said that everything is skewed, take the log transformation for all variables that have strictly positive values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also include and generate new features even if they don't seem to improve the models dramatically (just so we have stuff to write about)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all these comments after you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will define a baseline model for us to have a benchmark for our models to beat. Here, I will use the model of whereby the store sends a marketing letter to every customer (very inefficient but what is normally done!). From this, if our model does better than this, then it shows our model has promise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of people who actually respond is 16.61\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of people who actually respond is %.2f\"%((data['RESP'].sum()/data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People who respond 3611.0\n",
      "People who don't respond 21740.0\n"
     ]
    }
   ],
   "source": [
    "print(\"People who respond %.1f\"%data['RESP'].sum())\n",
    "print(\"People who don't respond %.1f\"%data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the cost/profit from sending a letter to everyone. We have 3611 true positives and 21740 false positives as a result of our strategy. Profit from true positive is 11.5 and cost of false positive is 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit from true positive is 41526.50 \n",
      "Cost from false positive is 54350.00 \n"
     ]
    }
   ],
   "source": [
    "print(\"Profit from true positive is %.2f \"%(data['RESP'].sum()*11.5))\n",
    "print(\"Cost from false positive is %.2f \"%(data.shape[0]*2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall cost from this strategy is 12823.50\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall cost from this strategy is %.2f\"%((data.shape[0]*2.5)-(data['RESP'].sum()*11.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost per person is $0.59\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost per person is $%.2f\"%(12823.50/data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline model makes a loss of 0.59 dollar on every customer it sends out material too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from this is 83.39\n"
     ]
    }
   ],
   "source": [
    "print('Error from this is %.2f'%(100*(1 - (data['RESP'].sum()/data.shape[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to note we have a massive error rate of 84% for our classification yet we hardly lose any money on each customer. This is because there is such a low associated cost with a False Positive whilst there is a massive payoff from a True Positive. Therefore this balances out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more information about the models I use in this: http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform valid phone number into dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Clothing_Store.csv')\n",
    "dummies = pd.get_dummies(data[['VALPHON']],  drop_first=True)\n",
    "data=data.join(dummies)\n",
    "\n",
    "del data['VALPHON']\n",
    "x_train = data.sample(frac=0.6, random_state=450411920)\n",
    "x_test = data[data.index.isin(x_train.index)==False]\n",
    "#Now we have final train/test which only has predictors whilst y_train/test are the response\n",
    "y_train = x_train.pop('RESP')\n",
    "y_test = x_test.pop('RESP')\n",
    "\n",
    "#Normalise the features for some models\n",
    "norm_train = preprocessing.normalize(x_train)\n",
    "norm_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training size is 13044 with 2162 number of yes respondents. Makes up around 16.574670346519476%.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Training size is {x_train.shape[0]} with {y_train.sum()} number of yes respondents. Makes up around {100*(y_train.sum()/x_train.shape[0])}%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test size is 8696 with 1449 number of yes respondents. Makes up around 16.66283348666053%.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Test size is {x_test.shape[0]} with {y_test.sum()} number of yes respondents. Makes up around {100*(y_test.sum()/x_test.shape[0])}%.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our yes respondents makes up approximately 17% of the training and test sample. Theres quite a bit of class imbalances but not on an extreme level. Normally we would want a range between 25-50 percent, so we shall drop some of the non-respondants in ONLY OUR TRAINING SET. We don't do balance test set since this data shouldn't be tampered with. This means that our algorithms have a chance to learn about BOTH individuals who respond and those who don't respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "'''This will randomly remove observations from the training dataset \n",
    "   IF the individual did NOT respond to marketing material'''\n",
    "rand_index = list(x_train.index.values)\n",
    "np.random.seed(10)\n",
    "for i in range(1,12000):\n",
    "    ind = random.choice(rand_index)\n",
    "    if(y_train[ind]==1):\n",
    "        continue\n",
    "    else:\n",
    "        x_train = x_train.drop(ind)\n",
    "        del y_train[ind]\n",
    "        rand_index.remove(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training size is 4445 with 2162 number of yes respondents. Makes up around 48.638920134983124%.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Training size is {x_train.shape[0]} with {y_train.sum()} number of yes respondents. Makes up around {100*(y_train.sum()/x_train.shape[0])}%.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved apprxomiately 50% split now between those who responded and those who didn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let define some new loss functions to take into account our cost-benefit matrix as we now want to minimise over the false negative, true positive, and a mixture of these two. http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer. We want to minimise the number of false positives and maximize the number of true positives according to cost-benefit matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def false_Negative_Loss(y_truth, y_pred):\n",
    "    '''Computes the False Negative rate and returns it.'''\n",
    "    fn = confusion_matrix(y_truth, y_pred)[1, 0]\n",
    "    return fn\n",
    "\n",
    "def true_Positive_Score(y_truth, y_pred):\n",
    "    '''Computes the True Positive rate and returns it.'''\n",
    "    tp = confusion_matrix(y_truth, y_pred)[1, 1]\n",
    "    return tp\n",
    "\n",
    "#A scorer is created made from the loss functions created earlier. We want to minimise this loss but maximize score.\n",
    "fn_loss = make_scorer(false_Negative_Loss, greater_is_better=False)\n",
    "tp_score = make_scorer(true_Positive_Score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A false negative has a 20% higher impact (in terms of cost) for the company. Therefore we should incorporate this when calculating a mix loss function with both the false negative and true positive rate. This means our algorithm wants to try predict positive when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixed_Loss(y_truth, y_pred):\n",
    "    '''Computes the False/True Negative and False/True Positive rate and returns a mixed loss function.'''\n",
    "    fn = confusion_matrix(y_truth, y_pred)[1, 0]\n",
    "    tp = confusion_matrix(y_truth, y_pred)[1, 1]\n",
    "    fp = confusion_matrix(y_truth, y_pred)[0, 1]\n",
    "    mixed_rate = (-11.5*tp) + (14*fn) - (2.5*fp)\n",
    "    return mixed_rate\n",
    "\n",
    "mixed_score = make_scorer(mixed_Loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate how each of our model performs from a confusion matrix.\n",
    "https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResultTable(rows, predictions):\n",
    "    '''Generates a table highlighting the results of each model.'''\n",
    "    columns=['Accuracy for No', 'Accuracy for Yes', 'Overall Accuracy']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        results.iloc[row,0] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,1] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,2] = (accuracy_score(y_test, pred))\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try to tune the hyperparameter in our models, we use this package called randomizedsearchcv. It randomly chooses hyperparameters for each model (rather than try all possible ones) in order to save computation time.\n",
    "\n",
    "This allows us to try out different hyperparameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "modelname = []\n",
    "models_tp = []\n",
    "models_fn = []\n",
    "\n",
    "comb_models = [models,models_tp,models_fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we tune our models with different loss/score functions in mind in order to see which one gives us the best overall results. We also use the accuracy score too in order for us to have a benchmark model as well for our defined loss/score functions to be evaluated agaisnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_metric = ['accuracy',fn_loss,tp_score]\n",
    "scoresname = [' Accuracy',' FN_loss',' tp_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with KNN with inspiration from:\n",
    "\n",
    "http://www.ritchieng.com/machine-learning-efficiently-search-tuning-param/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try setting from 1 - 25 neighbors\n",
    "k_range = range(1, 25)\n",
    "# we create a list. This allows us to see whether we should weigh all neighbours equally or weigh closer ones more\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the objects necessary for us to try cross-validation in order to locate best hyperparameters\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    knn = KNeighborsClassifier()\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring=score, n_iter=10, random_state=5)\n",
    "    #Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "    knnopt = rand.fit(x_train, y_train)\n",
    "    modelname.append('KNN' + name)\n",
    "    model_list.append(knnopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for KNN involves 4 neighbours and having uniform neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now constructing a graph for this\n",
    "k_range = range(1, 25)\n",
    "\n",
    "# list of scores from k_range\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'uniform')\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11ddfc198>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAETCAYAAADOPorfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9XYWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dcb77f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Neighbours vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that increasing number of neighbours improves accuracy. However, we need to be wary of this as eventually accuracy falls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    # Instantiate a Decision Tree classifier:\n",
    "    tree = DecisionTreeClassifier()    \n",
    "    # Instantiate the RandomizedSearchCV object:\n",
    "    tree_cv = RandomizedSearchCV(tree,param_dist, cv=10, scoring=score, n_iter=10, random_state=5)\n",
    "    treeopt = tree_cv.fit(x_train, y_train)\n",
    "    treeopt = treeopt.fit(x_train, y_train)\n",
    "    modelname.append('Decision Tree' + name)\n",
    "    model_list.append(treeopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now constructing a graph for this\n",
    "tree_range = range(2, 10)\n",
    "\n",
    "# list of scores from t_range\n",
    "t_scores = []\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in tree_range:\n",
    "    # 2. run Decision tree with different value for depth of tree\n",
    "    tree = DecisionTreeClassifier(max_depth = k, criterion='entropy', max_features = 8, max_leaf_nodes = None )\n",
    "    # 3. obtain cross_val_score for Decision tree with depth of k\n",
    "    scores = cross_val_score(tree, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for decision tree to t_scores list\n",
    "    t_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11ba1a7f0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAETCAYAAADOPorfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b9cdb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of Depth for Decision Tree(x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of Depth for Decision Tree')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Depth vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Similar interpretation to KNN graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(5,15),\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_split\": range(2,5),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              }\n",
    "\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    # Instantiate a Extremely Random Forest classifier:\n",
    "    randFor = RandomForestClassifier()\n",
    "    # Instantiate the RandomizedSearchCV object:\n",
    "    randFor_cv = RandomizedSearchCV(randFor,param_dist, cv=10, scoring=score, n_iter=10, random_state=5)\n",
    "    optrand = randFor_cv.fit(x_train, y_train)\n",
    "    optrand = optrand.fit(x_train, y_train)\n",
    "    modelname.append('Random Forest' + name)\n",
    "    model_list.append(optrand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-0c2840b6223a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Instantiate a logit model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlogit_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlogit_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodelname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logit L1'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                       )\n\u001b[0;32m-> 1687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m             for train, test in folds)\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#Logistic regression\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    # Instantiate a logit model:\n",
    "    logit = LogisticRegressionCV(cv=10, scoring=score)\n",
    "    logit = logit.fit(x_train, y_train)\n",
    "    modelname.append('Logit' + name)\n",
    "    model_list.append(logit)\n",
    "\n",
    "#Logistic regression with l1 pentalty\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    # Instantiate a logit model:\n",
    "    logit_l1 = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=10, scoring=score)\n",
    "    logit_l1 = logit_l1.fit(x_train, y_train)\n",
    "    modelname.append('Logit L1' + name)\n",
    "    model_list.append(logit_l1)\n",
    "\n",
    "#Logistic regression with l2 pentalty\n",
    "for score, model_list,name in zip(scores_metric,comb_models,scoresname):\n",
    "    '''Train cross-validation with 3 different loss functions. Then we store object into list and respective names.'''\n",
    "    # Instantiate a logit model:\n",
    "    logit_l2 = LogisticRegressionCV(penalty='l2', solver='liblinear', cv=10, scoring=score)\n",
    "    logit_l2 = logit_l2.fit(x_train, y_train)\n",
    "    modelname.append('Logit L2' + name)\n",
    "    model_list.append(logit_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some further models which we need not to worry about the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "NaiveB = GaussianNB()\n",
    "optnb = NaiveB.fit(x_train,y_train)\n",
    "models.append(optnb)\n",
    "modelname.append('Naive Bayes')\n",
    "\n",
    "#Linear Discriminant analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "optlda = LDA.fit(x_train,y_train)\n",
    "models.append(optlda)\n",
    "modelname.append('LDA')\n",
    "\n",
    "#Quadratic Discriminant analysis\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "optqda = QDA.fit(x_train,y_train)\n",
    "models.append(optqda)\n",
    "modelname.append('QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getResultTable3(rows, modelsUsed,model_num):\n",
    "    '''Generates evaluation table depending on which type of models we are looking at.'''\n",
    "    names = []\n",
    "    model_obj = []\n",
    "    #Retrieves which model we want to analyse based on the score function used to calculate it:\n",
    "    if model_num ==1:\n",
    "        names = rows[0:5:3] + rows[6::1]\n",
    "    elif model_num ==2:\n",
    "        names = rows[1:5:3]\n",
    "    else:\n",
    "        names = rows[2:5:3]\n",
    "\n",
    "    #Create dataframe to store results:\n",
    "    columns=['Overall Accuracy', 'Error Rate', 'SE', 'Sensitivity(TP)', 'Specificity(TN)', \n",
    "             'Precision', 'Profit', 'Profit Per Customer', 'CI for Profit U', 'CI for Profit L']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=names)\n",
    "    #Iterate through and compute predictions for models we are looking at:\n",
    "    predictions = []\n",
    "    for clf in modelsUsed:\n",
    "        pred = clf.predict(x_test)\n",
    "        predictions.append(pred) \n",
    "        \n",
    "    for row,pred in zip(range(0,len(names)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        error_rate = 1 - (accuracy_score(y_test, pred))\n",
    "        results.iloc[row,0] = (accuracy_score(y_test, pred))\n",
    "        results.iloc[row,1] = error_rate\n",
    "        se = np.sqrt(error_rate*(1- error_rate)/len(y_test))\n",
    "        results.iloc[row,2] = se\n",
    "        results.iloc[row,3] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,4] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,5] =  precision_score(y_test, pred)\n",
    "        results.iloc[row,6] = (11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1])\n",
    "        results.iloc[row,7] = ((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0]\n",
    "        results.iloc[row,8] = (((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0])+(1.96*se)\n",
    "        results.iloc[row,9] = (((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0])-(1.96*se)\n",
    "\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "def getResultTable2(rows, modelsUsed,model_num):\n",
    "    '''Generates evaluation table depending on which type of models we are looking at.'''\n",
    "    names = []\n",
    "    #Retrieves which model we want to analyse based on the score function used to calculate it:\n",
    "    if model_num ==1:\n",
    "        names = rows[0:11:3] + rows[12::1]\n",
    "    elif model_num ==2:\n",
    "        names = rows[1:11:3]\n",
    "    else:\n",
    "        names = rows[2:11:3]\n",
    "        \n",
    "  \n",
    "    #Create dataframe to store results:\n",
    "    columns=['Overall Accuracy', 'Error Rate', 'SE', 'Sensitivity(TP)', 'Specificity(TN)', \n",
    "             'Precision', 'Profit', 'Profit Per Customer', 'CI for Profit U', 'CI for Profit L']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=names)\n",
    "    #Iterate through and compute predictions for models we are looking at:\n",
    "    predictions = []\n",
    "    for clf in modelsUsed:\n",
    "        pred = clf.predict(x_test)\n",
    "        predictions.append(pred) \n",
    "        \n",
    "    for row,pred in zip(range(0,len(names)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        error_rate = 1 - (accuracy_score(y_test, pred))\n",
    "        results.iloc[row,0] = (accuracy_score(y_test, pred))\n",
    "        results.iloc[row,1] = error_rate\n",
    "        se = np.sqrt(error_rate*(1- error_rate)/len(y_test))\n",
    "        results.iloc[row,2] = se\n",
    "        results.iloc[row,3] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,4] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,5] =  precision_score(y_test, pred)\n",
    "        results.iloc[row,6] = (11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1])\n",
    "        results.iloc[row,7] = ((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0]\n",
    "        results.iloc[row,8] = (((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0])+(1.96*se)\n",
    "        results.iloc[row,9] = (((11.5*matrix[1][1]) - (14*matrix[1][0]) - (2.5*matrix[0][1]))/y_test.shape[0])-(1.96*se)\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATT, ONCE YOU ARE DONE RUNNING THE MODELS, USE GETRESULTTABLE2 NOT 3 FOR NEXT 3 BARS IN ORDER FOR IT TO WORK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity(TP)</th>\n",
       "      <th>Specificity(TN)</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Profit Per Customer</th>\n",
       "      <th>CI for Profit U</th>\n",
       "      <th>CI for Profit L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN Accuracy</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-14199.0</td>\n",
       "      <td>-1.633</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>-1.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Accuracy</th>\n",
       "      <td>0.745</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1877.5</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-19969.5</td>\n",
       "      <td>-2.296</td>\n",
       "      <td>-2.288</td>\n",
       "      <td>-2.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1521.5</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.755</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-1339.5</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Overall Accuracy  Error Rate     SE  Sensitivity(TP)  \\\n",
       "KNN Accuracy                       0.638       0.362  0.005            0.173   \n",
       "Decision Tree Accuracy             0.745       0.255  0.005            0.366   \n",
       "Naive Bayes                        0.829       0.171  0.004            0.240   \n",
       "LDA                                0.731       0.269  0.005            0.351   \n",
       "QDA                                0.755       0.245  0.005            0.362   \n",
       "\n",
       "                        Specificity(TN)  Precision   Profit  \\\n",
       "KNN Accuracy                      0.836      0.173 -14199.0   \n",
       "Decision Tree Accuracy            0.931      0.366   1877.5   \n",
       "Naive Bayes                       0.834      0.240 -19969.5   \n",
       "LDA                               0.929      0.351   1521.5   \n",
       "QDA                               0.911      0.362  -1339.5   \n",
       "\n",
       "                        Profit Per Customer  CI for Profit U  CI for Profit L  \n",
       "KNN Accuracy                         -1.633           -1.623           -1.643  \n",
       "Decision Tree Accuracy                0.216            0.225            0.207  \n",
       "Naive Bayes                          -2.296           -2.288           -2.304  \n",
       "LDA                                   0.175            0.184            0.166  \n",
       "QDA                                  -0.154           -0.145           -0.163  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Warning, this takes a while to run!\n",
    "getResultTable3(modelname, models, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity(TP)</th>\n",
       "      <th>Specificity(TN)</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Profit Per Customer</th>\n",
       "      <th>CI for Profit U</th>\n",
       "      <th>CI for Profit L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN FN_loss</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-10733.0</td>\n",
       "      <td>-1.234</td>\n",
       "      <td>-1.224</td>\n",
       "      <td>-1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree FN_loss</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.353</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Overall Accuracy  Error Rate     SE  Sensitivity(TP)  \\\n",
       "KNN FN_loss                       0.526       0.474  0.005            0.173   \n",
       "Decision Tree FN_loss             0.740       0.260  0.005            0.353   \n",
       "\n",
       "                       Specificity(TN)  Precision   Profit  \\\n",
       "KNN FN_loss                      0.839      0.173 -10733.0   \n",
       "Decision Tree FN_loss            0.920      0.353     40.0   \n",
       "\n",
       "                       Profit Per Customer  CI for Profit U  CI for Profit L  \n",
       "KNN FN_loss                         -1.234           -1.224           -1.245  \n",
       "Decision Tree FN_loss                0.005            0.014           -0.005  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable3(modelname, models_tp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity(TP)</th>\n",
       "      <th>Specificity(TN)</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Profit Per Customer</th>\n",
       "      <th>CI for Profit U</th>\n",
       "      <th>CI for Profit L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN FN_loss</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-10733.0</td>\n",
       "      <td>-1.234</td>\n",
       "      <td>-1.224</td>\n",
       "      <td>-1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree FN_loss</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-3173.5</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Overall Accuracy  Error Rate     SE  Sensitivity(TP)  \\\n",
       "KNN FN_loss                       0.526       0.474  0.005            0.173   \n",
       "Decision Tree FN_loss             0.785       0.215  0.004            0.394   \n",
       "\n",
       "                       Specificity(TN)  Precision   Profit  \\\n",
       "KNN FN_loss                      0.839      0.173 -10733.0   \n",
       "Decision Tree FN_loss            0.902      0.394  -3173.5   \n",
       "\n",
       "                       Profit Per Customer  CI for Profit U  CI for Profit L  \n",
       "KNN FN_loss                         -1.234           -1.224           -1.245  \n",
       "Decision Tree FN_loss               -0.365           -0.356           -0.374  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable3(modelname, models_fn, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From this, the best 2 models were:\n",
    "\n",
    "Recall that our Cost/Benefit values (express in terms of cost):\n",
    "\n",
    "True Negative: 0 since we don't send anything to a customer who would have bought something otherwise.\n",
    "\n",
    "True Positive: -14 + 2.5 = -11.5 (profit is negative cost. Thus, we have profit and cost to send mail)\n",
    "\n",
    "False Negative: 14 (Lost profit and therefore don't make money).\n",
    "\n",
    "False Positive: 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have models that made profit! Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
