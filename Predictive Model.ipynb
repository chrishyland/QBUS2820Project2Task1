{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Clothing_Store.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 predictors for 21740 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740, 51)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by: http://www.comp.dit.ie/btierney/Oracle11gDoc/datamine.111/b28129/classify.htm\n",
    "\n",
    "Here, it costs \\$2.5 to send direct mail marketing to a customer. So a false positive will mean a loss of $2.5 since we send mail for no reason (cite a random source to quote this price).\n",
    "\n",
    "Cost/Benefit values (express in terms of cost):\n",
    "\n",
    "True Negative: 0 since we don't send anything to a customer who would have bought something otherwise.\n",
    "\n",
    "True Positive: -14 + 2.5 = -11.5 (profit is negative cost. Thus, we have profit and cost to send mail)\n",
    "\n",
    "False Negative: -14 (Lost profit and therefore don't make money).\n",
    "\n",
    "False Positive: 2.5\n",
    "\n",
    "Talk and elaborate more about TN, TP, FN, and FP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean amount of money spent by typical customer is \\$114 whilst median was \\$92. Due to data being positively skewed (mean greater than median), we decide to take the average amount spent by a customer was \\$92. We assume profit is 15% of this, so profit made for each successful customer who is sent mail and responds, is \\$14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean amount spent by customer 113.89\n",
      "Median amount spent by customer 92.07\n",
      "Skewness of the amount spent by customer is 3.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean amount spent by customer %.2f\"%data['AVRG'].mean())\n",
    "print(\"Median amount spent by customer %.2f\"%data['AVRG'].median())\n",
    "print(\"Skewness of the amount spent by customer is %.2f\"%data['AVRG'].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21740.000000\n",
       "mean       113.889105\n",
       "std         87.249794\n",
       "min          0.490000\n",
       "25%         60.990000\n",
       "50%         92.070000\n",
       "75%        139.505000\n",
       "max       1919.880000\n",
       "Name: AVRG, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AVRG'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about whether False Negatives or False positives are worse. Seems like false negatives for me since if you send mail to someone who won't respond, you only lose 2 dollars (false positive) whilst if you fail to send it to someone who will respond, you lose \\$9.2 (false negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding/Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "#Compute how many people in dataset responded to marketing campain. RESP means whether they responded or not.\n",
    "print(\"%.2f\"%(data['RESP'].sum()/data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue here since in dataset, only 17% of observations actually responded to marketing campain. We have a MASSIVE class imbalance here. It will be difficult to obtain a good score for the sensitivity as a result.\n",
    "\n",
    "Let's explore more about this dataset and see if any patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a cluster variable which tells us what kind of customer (segment) they are from. Each type is associated with a number from the Microvision Market Segmentation System: http://www.tetrad.com/pub/prices/microvision.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dd37518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clust_type_count = data['CLUSTYPE'].value_counts()\n",
    "ax = sb.barplot(x =clust_type_count.index[:10], y= clust_type_count[:10])\n",
    "ax.set(xlabel='Cluster Type', ylabel='Count', title=\"Most prevalent customer clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, cluster 10 (home sweet home) is the most prevalent life style cluster in our data set. These are families with medium-high income. Analyse what the top 3-5 lifestyles are according to the microvision pdf. Appears customer tends to be rich families that are hihgly educated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE COPY AND PASTE THE CODE FOR THE FEATURE ENGINEERING/EDA TASK THAT YOU'VE DONE OVER HERE (ONLY THE ONES YOU FIND RELEVANT AND WORTH TALKING ABOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since you said that everything is skewed, take the log transformation for all variables that have strictly positive values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also include and generate new features even if they don't seem to improve the models dramatically (just so we have stuff to write about)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all these comments after you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data[['VALPHON']],  drop_first=True)\n",
    "data=data.join(dummies)\n",
    "\n",
    "del data['VALPHON']\n",
    "final_train = data.sample(frac=0.6, random_state=450411920)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "#Now we have final train/test which only has predictors whilst y_train/test are the response\n",
    "y_train = final_train.pop('RESP')\n",
    "y_test = final_test.pop('RESP')\n",
    "\n",
    "#Normalise the features for some models\n",
    "norm_train = preprocessing.normalize(final_train)\n",
    "norm_test = preprocessing.normalize(final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will define a baseline model for us to have a benchmark for our models to beat. Here, I will use the model of whereby the store sends a marketing letter to every customer (very inefficient but what is normally done!). From this, if our model does better than this, then it shows our model has promise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of people who actually respond is 16.61\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of people who actually respond is %.2f\"%((data['RESP'].sum()/data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People who respond 3611.0\n",
      "People who don't respond 21740.0\n"
     ]
    }
   ],
   "source": [
    "print(\"People who respond %.1f\"%data['RESP'].sum())\n",
    "print(\"People who don't respond %.1f\"%data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the cost/profit from sending a letter to everyone. We have 3611 true positives and 21740 false positives as a result of our strategy. Profit from true positive is 11.5 and cost of false positive is 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit from true positive is 41526.50 \n",
      "Cost from false positive is 54350.00 \n"
     ]
    }
   ],
   "source": [
    "print(\"Profit from true positive is %.2f \"%(data['RESP'].sum()*11.5))\n",
    "print(\"Cost from false positive is %.2f \"%(data.shape[0]*2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall cost from this strategy is 12823.50\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall cost from this strategy is %.2f\"%((data.shape[0]*2.5)-(data['RESP'].sum()*11.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost per person is $0.59\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost per person is $%.2f\"%(12823.50/data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline model makes a loss of 0.59 dollar on every customer it sends out material too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more information about the models I use in this: http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to store the results from our models\n",
    "pred = []\n",
    "method = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(final_train,y_train)\n",
    "predneigh = neigh.predict(final_test)\n",
    "pred.append(predneigh)\n",
    "method.append('KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adaptive Boosting\n",
    "regr = AdaBoostClassifier(learning_rate = 1, n_estimators = 350)\n",
    "model.append(regr)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "pred.append(adapred)\n",
    "method.append('AdaptiveBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quadratic Discriminant analysis\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "QDA.fit(norm_train, y_train)\n",
    "predQDA = QDA.predict(norm_test)\n",
    "pred.append(predQDA)\n",
    "method.append('QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear Discriminant analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(norm_train, y_train)\n",
    "predLDA = LDA.predict(norm_test)\n",
    "pred.append(predLDA)\n",
    "method.append('LDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "DT = DecisionTreeClassifier(random_state=0)\n",
    "DT.fit(final_train,y_train)\n",
    "predDT = DT.predict(final_test)\n",
    "pred.append(predDT)\n",
    "method.append('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "RandomFor = RandomForestClassifier(max_depth=None,min_samples_split=2)\n",
    "model.append(RandomFor)\n",
    "RandomFor = RandomFor.fit(final_train,y_train)\n",
    "randomforpred = RandomFor.predict(final_test)\n",
    "pred.append(randomforpred)\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random Forest\n",
    "Extratree = ExtraTreesClassifier(max_depth=None,min_samples_split=2)\n",
    "model.append(Extratree)\n",
    "Extratree = Extratree.fit(final_train,y_train)\n",
    "predFinalExtRandomForest = Extratree.predict(final_test)\n",
    "pred.append(predFinalExtRandomForest)\n",
    "method.append('Extreme Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "GradBoost = GradientBoostingClassifier(n_estimators=350, learning_rate=0.1,\n",
    "                                 max_depth=1, random_state=0)\n",
    "model.append(GradBoost)\n",
    "GradBoost = GradBoost.fit(final_train,y_train)\n",
    "predGradBoost = GradBoost.predict(final_test)\n",
    "pred.append(predGradBoost)\n",
    "method.append('Gradient Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "NaiveB = GaussianNB()\n",
    "model.append(NaiveB)\n",
    "NaiveB = NaiveB.fit(norm_train, y_train)\n",
    "predNaiveB = NaiveB.predict(norm_test)\n",
    "pred.append(predNaiveB)\n",
    "method.append('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "LogReg = LogisticRegression(random_state=450411920)\n",
    "model.append(LogReg)\n",
    "LogReg = LogReg.fit(final_train,y_train)\n",
    "predLogReg = LogReg.predict(final_test)\n",
    "pred.append(predLogReg)\n",
    "method.append('Logit Reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate how each of our model performs from a confusion matrix.\n",
    "https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates us a table for results\n",
    "def getResultTable(rows, predictions):\n",
    "    columns=['Accuracy for No', 'Accuracy for Yes', 'Overall Accuracy']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    \n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        results.iloc[row,0] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,1] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,2] = (accuracy_score(y_test, pred))\n",
    "        \n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaptiveBoost</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extreme Random Forest</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logit Reg</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy for No  Accuracy for Yes  Overall Accuracy\n",
       "KNN                              0.836             0.200             0.789\n",
       "AdaptiveBoost                    0.876             0.594             0.850\n",
       "QDA                              0.902             0.390             0.782\n",
       "LDA                              0.866             0.623             0.850\n",
       "Decision Tree                    0.876             0.381             0.794\n",
       "Random Forest                    0.863             0.558             0.842\n",
       "Extreme Random Forest            0.860             0.570             0.842\n",
       "Gradient Boost                   0.871             0.655             0.855\n",
       "Naive Bayes                      0.891             0.427             0.807\n",
       "Logit Reg                        0.833               NaN             0.833"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm2df(cm, labels):\n",
    "    df = pd.DataFrame()\n",
    "    # rows\n",
    "    for i, row_label in enumerate(labels):\n",
    "        rowdata={}\n",
    "        # columns\n",
    "        for j, col_label in enumerate(labels): \n",
    "            rowdata[col_label]=cm[i,j]\n",
    "        df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
    "    return df[labels]\n",
    "\n",
    "## to use, first generate confusion matrix:\n",
    "#cm = confusion_matrix(expected, predicted)\n",
    "## then convert to pandas DataFrame:\n",
    "#cm_as_df=cm2df(cm,dataset.target_names)\n",
    "## and output:\n",
    "#cm_as_df\n",
    "\n",
    "def precision_recall_fscore_support_metrics2df(prfs, labels):\n",
    "    df = pd.DataFrame()\n",
    "    for p,r,f,s,label in zip(prfs[0], prfs[1], prfs[2], prfs[3], dataset.target_names):\n",
    "        rowdata={}\n",
    "        rowdata['precision']=p\n",
    "        rowdata['recall']=r\n",
    "        rowdata['f1-score']=f\n",
    "        rowdata['support']=s\n",
    "        df = df.append(pd.DataFrame.from_dict({label:rowdata}, orient='index'))   \n",
    "    return df[['precision','recall','f1-score','support']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>6337</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>772</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x    y\n",
       "x  6337  910\n",
       "y   772  677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,predNaiveB)\n",
    "cm2df(cm,['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA confusion matrix is:\n",
      "[[6004 1243]\n",
      " [ 654  795]]\n",
      "Accuracy of predicting Yes is 0.902\n",
      "Accuracy of predicting No is 0.390\n",
      "Overall accuracy is 0.782\n",
      "\n",
      "LDA confusion matrix is:\n",
      "[[7028  219]\n",
      " [1087  362]]\n",
      "Accuracy of predicting Yes is 0.866\n",
      "Accuracy of predicting No is 0.623\n",
      "Overall accuracy is 0.850\n",
      "\n",
      "Naive Bayes confusion matrix is:\n",
      "[[6337  910]\n",
      " [ 772  677]]\n",
      "Accuracy of predicting Yes is 0.891\n",
      "Accuracy of predicting No is 0.427\n",
      "Overall accuracy is 0.807\n",
      "\n",
      "Best model is LDA\n",
      "Accuracy of the model is 0.850\n"
     ]
    }
   ],
   "source": [
    "#If we want to actually see a confusion matrix\n",
    "maxscore = 0\n",
    "bestmodel = 'none'\n",
    "for prediction, name in zip(pred,method):\n",
    "    print('{} confusion matrix is:'.format(name))\n",
    "    matrix = confusion_matrix(y_test, prediction)\n",
    "    print(matrix)\n",
    "    print('Accuracy of predicting No is %.3f'%(matrix[0][0]/(matrix[0][0]+matrix[1][0])))\n",
    "    print('Accuracy of predicting Yes is %.3f'%(matrix[1][1]/(matrix[0][1]+matrix[1][1])))\n",
    "    print('Overall accuracy is %.3f' % (accuracy_score(y_test, prediction)))\n",
    "    print('')\n",
    "    if (accuracy_score(y_test,prediction)>maxscore):\n",
    "        maxscore = accuracy_score(y_test,prediction)\n",
    "        bestmodel = name\n",
    "\n",
    "print('Best model is {}'.format(bestmodel))\n",
    "print('Accuracy of the model is %.3f' %(maxscore))\n",
    "    #8696 is total observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Gradient Boosting was the most accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret a confusion matrix, the column 1 and 2 represent the model predicting Yes or No. Then the rows represent were they actually yes or no. The [0,0] entry means that we predicted that many to be Yes, and it turns out that we were correct in predicting those, so that tells us how many yes observations we predicted correctly. Likewise, the [1,1] entry means how many no's we predicted correctly. The bottom left, [1,0] entry means we predicted yes, but was actually no and [0,1] entry is the vice versa. Conclusively, the diagonals of the matrix tells us how accurate are our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to tune the hyperparameter in our models, we use this package called randomizedsearchcv.\n",
    "\n",
    "This allows us to try out different hyperparameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "modelname = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with KNN with inspiration from:\n",
    "\n",
    "http://www.ritchieng.com/machine-learning-efficiently-search-tuning-param/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try setting from 1 - 25 neighbors\n",
    "k_range = range(1, 25)\n",
    "\n",
    "# we create a list. This allows us to see whether we should weigh all neighbours equally or weigh closer ones more\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the objects necessary for us to try cross-validation in order to locate best hyperparameters\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "knnopt = rand.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.834\n",
      "{'weights': 'uniform', 'n_neighbors': 22}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=22, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%rand.best_score_)\n",
    "print(rand.best_params_)\n",
    "print(rand.best_estimator_)\n",
    "models.append(knnopt)\n",
    "modelname.append('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for KNN involves 22 neighbours and having uniform neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7391884083841449, 0.8200690066610925, 0.79262347447833981, 0.82489923806123699, 0.81171339922396868, 0.82804305752590679, 0.82152594443765903, 0.83011278760604679, 0.82712304700344796, 0.83271991469292261, 0.83179966929414972, 0.83317968507783802, 0.83218322231512887, 0.83387010400323169, 0.83325660707071647, 0.83387010400323192, 0.83302666315918028, 0.83394690855795339, 0.83379365176298159, 0.83394690855795317, 0.83387033887954587, 0.83402359567451767, 0.83402359567451767, 0.83417673503133238]\n"
     ]
    }
   ],
   "source": [
    "#Now constructing a graph for this\n",
    "k_range = range(1, 25)\n",
    "\n",
    "# list of scores from k_range\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'uniform')\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, final_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x120af7c88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XHW9//HXO2ubdEvatHTfWdoCLQ3IqiCiICAXvSq4\nIHUBERCuXhTv9brrvVeu/tSLV0TlgoLsKAgIKBcQAaUrtKUspXRLt7RJkzRpO0nm8/vjnEmn08nk\nZJlkknyej8c8MnPWz5yZnM98v9/z/R6ZGc4551xH8vo6AOecc/2DJwznnHOReMJwzjkXiScM55xz\nkXjCcM45F4knDOecc5F4wujnJN0k6d8iLnurpO9kmG+SZvVcdC5bJH1D0u3h8ymS9kjK72jZLu5r\ntaTTu7q+Gzg8YfQxSesl7ZBUmjTt05KejrK+mX3WzL6dtQAHEEkfkbQkPLlulfRHSaf2dVzdZWYb\nzWyYmbV2d1vpflSY2Vwze7q72+5gny2SxmdrH65neMLIDfnANX0dRG+RVNAH+/wC8CPge8A4YArw\nU+B97Szf6zEORuEPpQ8AdcDHennf/hl3kieM3HAD8M+SRqWbKelISX+SVCPpNUkfSpp30C9CSV8K\nfz1vCUsqqdVMZZIekdQg6e+SZqbs7r2S1knaKekGSXnhdvMkfVXShrBE9GtJI8N5p0vanBLzeknv\nCp9/Q9J9km6XVA9cKumE8Nd+vaTtkn7YzntfI+m8pNcFkqolHSdpSLjNXZJ2S1osaVyabYwEvgVc\naWYPmFmjmTWb2cNm9qUMMRZL+lF4LLeEz4vD5cdIejjcb42kZ5OO1ZclVYXH+DVJZ7bz3v4o6aqU\naS9Jen/4/MeSNoXHaKmk09rZzrTwcy4IX0+X9Ey4/z8BY1KWv1fSNkl1kv4iaW44/TLgo8CXwlLY\nH9J8lpmOyemSNkv6Yvgd2SppUbqYk3wA2B1+Pp9IiTNf0r9IejN8L0slTQ7nzU36n9gu6V/C6an/\nDwd9N8P38mVJLwON4ffp+qR9vCLpwpQ4PhN+DxPzj5N0naT7U5b7iaQfd/B++zcz80cfPoD1wLuA\nB4DvhNM+DTwdPi8FNgGLgAJgAbATmBPOvzVpvbOBbcBcoAS4HTBgVtKyu4ATwm3dAdyVFIsBTwHl\nBL/AXwc+Hc77JLAWmAEMC+P9TTjvdGBzuvcVPv8G0Az8A8GPlKHAC8DHw/nDgBPbOT5fA+5Ien0u\nsCZ8fjnwh/C95gMLgRFptnE20AIUZPgc0sX4LeBvwFigAnge+Ha4/L8DNwGF4eM0QMAR4ec1IVxu\nGjCznX1eAjyX9HoOwcmzOHz9MWB0+Fl9MfxshyTFe3vSPizx/sJj+0OgGHg70JBYNumzHB7O/xGw\nImnerYTfp3Y+y0zH5PTwOH8rPCbvBZqAsgzH/Ung+wSlvhZgYdK864CV4TEVcGx4PIYDW8NjMiR8\n/bZ08ZPy3QzfywpgMjA0nPZBYEL4uX8YaATGJ82rAo4PY5gFTAXGh8uNCpcrAHYkxz8QH30ewGB/\ncCBhzCMolldwcML4MPBsyjo/B74ePm/7BwFuAf49ablZHJowfpk0/73Aq0mvDTg76fXngCfD508C\nn0uadwTBCbYg9Z8y+X2Fz78B/CVl/l+AbwJjOjg+swhOeCXh6zuAr4XPP0lwwjqmg218FNjWwTLp\nYnwTeG/S6/cA68Pn3wIeTBzblHh3hJ9pYQf7HB6edKaGr78L3JJh+Vrg2KR4D0kYBIm+BShNWu+3\nJCWMlG2OCtcdmfp9auezzHRMTgf2kpSYw2PR3o+BKUAcmB++fhz4cdL814AL0qx3MbC8nW0eFH/q\ndzN8L5/s4HNZkdhvGNM17Sz3R+Az4fPzgFcybXcgPLxKKkeY2SrgYeD6lFlTgbeFVR+7Je0mOAEe\nlmYzEwh+3SZsSrPMtqTnTQS/7pMlr7Mh3GZi2xtS5hUQ/DKMIjWWTwGHA6+GVUnnpVkHM1sLrAHO\nl1RC0Obw23D2bwj+oe8Kq0e+L6kwzWZ2AWPUcZ11aozp3nPieNxAUOJ6QkEV3vVJ8V5LcELfIeku\nSRMAwmqexGOKmTUAjwAXhdu8mCAhEi7/z2FVSF34uY8kpXopjQlArZk1psSd2Ga+pP8Iq2DqCU6g\nRNhu8vbbOyYAu8ysJel1uu9YwscJSosrwtd3AB9J+gwnEySoVO1Nj+qgz1nSJZJWJP1/zePA8ci0\nr9s40O7yMYLv44DmCSO3fB34DDAxadom4BkzG5X0GGZmV6RZfyswKen15C7EkLzOFGBL+HwLQfJK\nntcCbCf4lVySmKHg8s6KlO0eNCyymb1hZhcTVG38J3Cfkq4US3Enwcn0AoJfcWvDbTSb2TfNbA5w\nMsGvvEvSrP8CsJ+guimT1KGb073nLeG+G8zsi2Y2gyCJfSHRVmFmvzWzU8N1LXx/hJ9b4rEx+b1J\nOomgeuUpgLC94kvAhwiqdEYRlEDVwXvYStBOlXwspyQ9/wjBcXwXQQKaFk5PbLej4avbPSZdcAkw\nI2xP2UZQjTaGoOQLwXc/tY0tMX1GO9s86LtI+h9Wbe9R0lTgF8BVwOjwOK/iwPFoLwaA3wPHSJpH\n8N27o53lBgxPGDkkPBHeDXw+afLDwOGSPi6pMHwcL+moNJu4B1gk6ajw13ik/hkprpNUFjYuXhPG\nA8GJ7Z/CBtVhBFcb3R3+mnwdGCLp3PDX4VcJ6sfbJeljkirMLE5Qbw9B9UQ6dwHvBq7gQOkCSWdI\nOjpMUPUEVWSHbMPM6gjaQn4q6R8klYTH8RxJ388Q5p3AVyVVSBoTbiPR9+E8SbMkieBE3grEJR0h\n6Z1hQ/A+giqa9t4XwKMEJ+BvERzPxLLDCRJyNVAg6WvAiAzbSbzXDcAS4JuSihRcNnx+0iLDCZLn\nLoIT6/dSNrGd9k/GkOGYdEaYIGcStKfNDx/zCD7fRNL/JfBtSbMVOEbSaIL/ifGSrlXQCD9c0tvC\ndVYQXLhRLukwgtJeJqUECaQ6jGtRGEfCLwkuSFkYxjArTDKY2T7gvjDmF5N+BAxYnjByz7cIvsRA\n8EuW4GR5EcEvuW0Ev1gPOSGb2R+BnxD8Sl1L0DgJwQkiqgeBpQT/eI8Avwqn30JQ5P4L8BbByfDq\ncL91BO0dvyRoIGwEDrpqKo2zgdWS9gA/Bi4ys73pFjSzrQSlhJM5kMAg+PV4H0GyWAM8QzvVAmb2\nA+ALBMmsmuCX41UEvxLb8x2Ck+/LBI2vy8JpALOBPwN7wtj+x8yeIvhc/oPgwoRtBCWor7S3AzPb\nT3ABwbtISoYEVW2PESTjDQTHO10VYzofAd4G1BCUWn+dNO/X4faqgFc48B1J+BUwJ6yeSXdsMh2T\nzvgE8KCZrTSzbYkHwXfhPEnlBCWOe4AnCD7jXxE0VDcAZxEkwm3AG8AZ4XZ/A7xEUNX2BAd/Xw5h\nZq8APyD4DLcDRwPPJc2/l6Bt6bcEbWm/J7goJOG2cJ0BXx0FoLDBxg1AYSlkFcFVNy0dLe+c6xxJ\nU4BXgcPMrL6v48k2L2EMMJIuDIvpZQQlkT94snCu5ynod/MFgkvTB3yyAE8YA9HlBJcyvklQr56u\ncdw51w3hRQX1BFVjX+/jcHqNV0k555yLxEsYzjnnIhlQg2+NGTPGpk2b1tdhOOdcv7F06dKdZpba\nbyqtAZUwpk2bxpIlS/o6DOec6zckbeh4qYBXSTnnnIvEE4ZzzrlIPGE455yLxBOGc865SDxhOOec\ni8QThnPOuUg8YTjnnItkQPXDcM71T63xYIii/LyO7g/V/f20xOPkS+TnieB2Jl1jZrTGjeZWI9YS\nJ9YapznpEWsxrMP7UaVuE+JmbevHWuM0t4Tba43T3JqYlzStxSguzOOz72jvPk89xxOGc/1AU6yF\nF9+q4bm1O/nbuhpa48bYEcVUDCtm7Ihixg4fwtjhxVQMD5+PKGZIYX7Gbe5vaaW6YT87Gvazo34/\n1Xv2U12/jx0N+9umN8VamFhWwpTyoUwpL2FKeQmTw7/Dh6S7G277WlrjbNm9j7d2NbJ+ZyNvhY/1\nuxrZXLuX1riRJyjMz6MoP4/CgsRfHZiWn0dhfvi6IKggSZw8206mbSfscFrSyTyecv6WIF8iL08U\n5KnteX6eyJPIzwvmS6IlHj8kOeTKUHwVw4s9YTjXH9Tva+blTXVsqm1iSnkJMyuGMW5Ecbd+vba0\nxnm5qo7n3tjJX9fuZNnGWppbjaL8PI6bOorSogJ2NOxnzdZ6du6Jtf1CTza8uICKEcVhIhlCvqB6\nT5AcdjTsp25v8yHr5AlGDzuQiCYWDKVq915e2rT7kOXLSgoPSiCJx9gRQ9hWdyAxrN/ZyFu7GtlU\n00Rz64E4S4vymTamlHkTR3LeMeMpLshvO+G3JYEWO3Raa/DLu2FfCwoTTElRwUGJpC25JCWbooJg\nWn6eaI0HpYN4WEpoNSMeN1rj0BqP02rB83hinllSwgq2W9z2PC/ch9r2kUhsXfkOFOSpbRtFBQfe\n0yFJM+l9Zrtk1hZbr+zFuT7y9Gs72LJ7H9PGlDB9TCnjhg8hrxv/XK1x4/XtDSzfuJsVm2pZvnE3\na6v3HPJLs7Qon5ljhzGzYhgzK0qDv2OHMXV0CcUFh/7yNzPerN7DX9/YyV/X7uLv63bRsD84Ic6d\nMIJPnjqdU2aO4fhp5QwtOnj9eNyoaYq1lRJ2JJUSgpLCPl7evDsolQwvZmbFME6cMZqxww+UToKS\nSTHlpUUU5Kdv2qxramZTbRMbaw48NtU0saqqjsdWbaMlTdIaUpjHtNGlHD52OO+ZexjTR5cybUwp\n08aUUDGse0nV9b4BNbx5ZWWl+VhSDoIT8P/78xv85Mk3DpqeOIFNC09c08eUMG10KdMrStOewHbU\n72P5pt2s2LSb5RtreXlzHU2xViD4hT1/8igWTClj/uRRTB9TyqaaJt6s3sOb1Y3B3x172FK3r217\neaKtFDJz7DDGjxzCyqo6nlu7k+31wZ10p5SXcMqsMZw6awwnzRxNeWlRlo9W97W0xtlWv4+NNU1s\nr9/HuBFDeiRBu+yTtNTMKiMt6wnDDTTNrXG+8sBK7lu6mQ8unMTnz5zNhl1NkatIpo0pBYMVm3ZT\ntTu4zXhhvpgzfsRBCWLq6JJIv5Ab97fw1s4DCSSRTNbtbCTWEqespJCTwwRxyswxTBldkrVj41wq\nTxhu0GrY18zn7ljGs2/s5Np3zeaaM2e3e1LP1AjbGjfmTx7VliDmThjRYSNyZ7XGjeqG/YwdXuy/\nwl2f6UzC8DYMN2Bsq9vHolsX8/r2Br7/gWP40PGTMy5fkJ/HlNElTBldwjsOj3Q7gB6VnycOGzmk\n1/frXFd5wnB9Ih63Hv1V/fr2Bi695UXq9jZzy6XH90kCcG6g857ertc9uKKKo772GF+85yXW7mjo\n9vZeeHMXH/jZ8zTHjbsvP8mThXNZ4iUM16verN7DVx5YyWEjh/Doyq3cv2wz754zjitOn8mCKWWd\n3t6DK6q47t6XmTK6hFsXHc+kMm8wdi5bPGG4XrOvuZUr71hGcUEed192EkUFedz6/Hpue349T7yy\nnZNmjOaK02dy2uwxHV59ZGbc9Mw6/vOxVzlhejm/+HglI0s61/PYOdc5njBcr/nuI2t4dVsDt1xa\n2dbY+4WzDufyt8/gzhc38otn13HJLS8yb+IIrnjHLM6ed1jaHqytcePrD63i9r9t5LxjxvODDx2b\ntjOcc65necJwbW57fj1mxqWnTO/xbf9x5VZ+87cNfOa06bzzyHEHzSstLuDTp83g4ydN5ffLq/j5\nM+u48rfLmD6mlMvfPoMLj5vYlhD2xlq5+s7l/HnNdi5/+wy+fPaRfkmqc73E+2E4AGobY7zte08S\na43zhbMO5/Nnzu6xbW+qaeK9P3mWGRXDuPfyk9oGjWtPa9x4YvU2/ufpN1lZVcfY4cV8+rTpnD13\nPJ+/azkvbd7NN983l0tOmtZjMTo3WHk/DNdpv19RRaw1zmmzx/DDP71OYX4eV5ze/dEvYy1xrrpz\nOQA3Xrygw2QBQf+Ec44ez9nzDuO5tbv42TNr+d6jr/K9R1+luCCPmz62kPfMPazbsTnnOscThsPM\nuHvxJo6dNJJbF53AP929gv987FUK88WnT5vRrW3f8PirvLRpNz/76HFMLu/cFUySOHX2GE6dPYYV\nm3Zz75JN/OPCSV26mso5132eMBwvb67j1W0NfPfCeeTniR9+6FiaW+N855E1FBXkdbnq5/9e3c4v\nnn2Lj584lXOOHt+tGBPDdDjn+o533HPctXgTQwvzed+xE4BgyIyfXLyAs+aM42sPrua3f9/Y6W1u\nrdvLF+95iaPGj+Bfzz2qp0N2zvUBTxj9wI76fR0v1EVNsRb+8NIWzj1m/EF3UCvMz+PGjyzgjCMq\n+Nffr+TeJZsib7OlNc41d65gf0ucGz+yoMcH7XPO9Q1PGDlu6YZaTvjekzz16o6sbP+Rl7eyZ38L\nH04zUF9xQT4/+9hCTp01hi/d/zK/X14VaZs/efINXlxfw3f+YR4zK4b1dMjOuT7iCSPHLV5fA8CP\nn3yDbFwCfffiTcyoKKVyavqG5CGF+dz88UpOnD6aL9yzgkde3ppxe8+t3cl/P7WWf1w4ifcfN6nH\n43XO9R1PGDluVVUdENzM57m1u3p022t3NLBkQy0XHT8541AcQ4vy+eUnKlk4tYzP37Wcx1ZtS7tc\ndcN+rr17BTPGlPKtC+b2aKzOub7nCSPHraqq451HjmXciGJufOqNjlfohHuWbKYgT5FKAqXFBfzv\nohM4ZtJIrr5zGU+u2X7Q/Hjc+MI9K6jf28xPP3ocJUV+AZ5zA40njBxWv6+Z9buaWDi1jMvePpO/\nrathSVhF1V2xljj3L93Mu44ax5hhxZHWGVZcwK2LTuCo8SO44vZlPPN6ddu8nz3zJs++sZOvnz+X\nIw8b0SMxOudyiyeMHLa6qh6AuRNGcPEJkykvLeLGp9b2yLafXLOdXY0xPnxC5rvSpRo5tJBff/IE\nZo0dxmW/XsLza3eyZH0NP/zT65x7zHgu7uT2nHP9hyeMHLZ6S9B+MW/iSEqKCvjUqdN5+rVqVm6u\n6/a2716yifEjh/D22Z2/2dCokiJu//TbmDa6lE/dtoTP3bGMiaOG8u/vP7rDYcmdc/2XJ4wctrKq\njvEjh7RVGX38pKkMH1LAT7tZytiyey/PvF7NBxdOSjt8eBTlpUHSmDBqCLVNMW78yAJGDPH7UTg3\nkGU1YUg6W9JrktZKuj7N/JGS/iDpJUmrJS0Kp0+W9JSkV8Lp12Qzzly1qqqOeRNHtr0eMaSQS0+e\nxmOrt/H69q7f2vTeJZsB+GBl96qPKoYX88DnTuGP15zGMZN82A7nBrqsJQxJ+cBPgXOAOcDFkuak\nLHYl8IqZHQucDvxAUhHQAnzRzOYAJwJXplm3T8Va4uxrbs3a9hv3t7BuZyPzJow8aPqiU6ZTUpTP\n/3SxlBGPG/cs2cQpM8d0ejDAdEYOLWTW2OHd3o5zLvdls4RxArDWzNaZWQy4C7ggZRkDhiuo+B4G\n1AAtZrbVzJYBmFkDsAaYmMVYO+26+17i8t8szdr2X9lajxnMm3jwFUflpUV89G1TeOilLWzY1djp\n7T735k6qdu9N27PbOecyyWbCmAgkD0C0mUNP+jcCRwFbgJXANWYWT15A0jRgAfD3dDuRdJmkJZKW\nVFdXp1skK96s3sMLb+7KWikj0WHv6IkjD5n3mdNmUJCfx8+efrPT271r8SZGlRTy7rnjOl7YOeeS\n9HWj93uAFcAEYD5wo6S2n9SShgH3A9eaWX26DZjZzWZWaWaVFRWdv+Knq2obm4m1xllZ1f0rltJZ\nWVVHxfBixo4Ycsi8sSOG8OHKydy/bDNbdu+NvM2axhh/Wr2dCxdM9HtgO+c6LZsJowpIrveYFE5L\ntgh4wAJrgbeAIwEkFRIkizvM7IEsxtklNY0x4MBYTz1tdVV92tJFwuXvmIEZ3PyXdZG3+bvlwV31\nvDrKOdcV2UwYi4HZkqaHDdkXAQ+lLLMROBNA0jjgCGBd2KbxK2CNmf0wizF2yd5YK3vDqqil62uz\nsv03djQwb0L7PaYnlZVw4YKJ3PniRqob9ne4zeCuehuZP3mU98R2znVJ1hKGmbUAVwGPEzRa32Nm\nqyV9VtJnw8W+DZwsaSXwJPBlM9sJnAJ8HHinpBXh473ZirWzapuC0kVxQR5LN9YSj/fsKLJrttUT\nNw66pDadK06fSXNrnF/+teNSxvJNu3l9+x4vXTjnuiyrI8SZ2aPAoynTbkp6vgV4d5r1/grkbJfh\nRHXUabMr+POa7bxZvYfZ43ru0tJEg3dHCWNGxTDOPWYCt7+wgSveMZNRJUXtLnvP4k2UFOVzfnhX\nPeec66y+bvTulxIJ491zgiuNlmzo2WqpVVV1lJcWMX7koQ3eqa48YyaNsVb+97n17S6zZ38LD720\nhfOOGc+wYh9F1jnXNR0mDEnnS/LEkiRRJXXc1FGMLi1iSQ+3Y6yqqmfexJGRxmU68rARnDVnHLc+\nv549+1vSLvPIy1toirV6dZRzrluiJIIPA29I+r6kI7MdUH+QKGGUlxazcGoZSzb03JVS+5pbeX17\n5gbvVFedMYu6vc3c/rcNaeffvXgTs8YO47gp6e+q55xzUXSYMMzsYwQd594EbpX0QthZbtCOB1Hb\nGEMKhsWonFbGhl1Nka5UiuL17Q20xC3jJbWpjp08itNmj+GXz647pCPh69sbWLZxd4d31XPOuY5E\nqmoKO83dRzC8x3jgQmCZpKuzGFvOqmmKMWpoIfl5YuHUcgCW9lApY2XEBu9UV79zNjv3xLjrxY0H\nTb978SYK88WFC3JqZBXnXD8UpQ3jfZJ+BzwNFAInmNk5wLHAF7MbXm6qbWymrDS4ImnexBEUF+T1\nWDvGqqp6Rg4tZFLZ0E6td8L0ck6YVs7P/7KOWEswusr+llZ+t7yKs+aMY3TEu+o551x7opQwPgD8\nPzM72sxuMLMdAGbWBHwqq9HlqJrGGOXhJazFBfkcO2kUi3voSqlgSPMRXao+uuqds9hat48HlgXD\nl//5lR3UNMb48PFTeiQ259zgFiVhfAN4MfFC0tBwQEDM7MmsRJXjaptibSUMgIXTylhdVcfeWPcG\nIoy1xHltW8MhQ5pHddrsMRwzaST/8/SbtLTGuWvxRiaMHMKps8Z0Ky7nnINoCeNeIHkE2dZw2qC1\nqzHG6KSEcfy0Mlrixkubd3dru69vbyDWGu90+0WCJK48YxYba5r4+V/W8de1O/lg5eQu31XPOeeS\nRUkYBeH9LAAIn7ffpXiAMzNqGw8uYSQuV13SzYEIk+/h3VVnHTWOI8YN54bHXwPgg5WTuhWTc84l\nREkY1ZLel3gh6QJgZ/ZCym0N+1toiVtbGwbAqJIiZo8d1u0e3yur6hheXMDUbtwJLy9PfO6MmQCc\nOmsMk8q6f1c955yDaGNJfRa4Q9KNBOM7bQIuyWpUOaw27LSXXMIAqJxWzsMvbyEeN/K6WAW0qqqe\nORNGdHn9hPOOmcCLb9Xw/uO8dOGc6zlROu69aWYnEtyX+ygzOzm8d8WgdKCXd+FB0yunltGwr4XX\ndzR0abstrXHWbM18D4yo8vPEdy88moVTvWe3c67nRBqJTtK5wFxgSOJyTzP7VhbjylmJcaTKSlJL\nGIl2jNou3W9ibfUe9rd0vcHbOeeyLUrHvZsIxpO6mqBK6oPA1CzHlbNqGpsBKE+pkppSXsKYYcUs\n7WI7xqqq4A608yb6zY2cc7kpSqP3yWZ2CVBrZt8ETgIOz25Yuau2rUrq4IQhieOnlXX5lq2rquoo\nKcpn+phh3Y7ROeeyIUrC2Bf+bZI0AWgmGE9qUNrVGKMwX2nvK7Fwahmba/eyvX5fmjUzW1VVx5zx\nI7zPhHMuZ0VJGH+QNAq4AVgGrAd+m82gclltY4yykqK0Q3dUTgsGIuzsuFKtcWP1lnpvv3DO5bSM\nCSO8cdKTZrbbzO4naLs40sy+1ivR5aCaptgh1VEJcyeMYEhhXqfvj/HWzj3sbW71hOGcy2kZE4aZ\nxYGfJr3eb2Z1WY8qhyVKGOkU5ucxf/KoTpcwEkOa98Qltc45ly1RqqSelPQB+d13gMwlDIDKqeW8\nsrWexnZul5rOqqp6igvymFlR2hMhOudcVkRJGJcTDDa4X1K9pAZJ9VmOK2cF40gVtju/cloZrXHj\npU3RByJcVVXHUeNHUJDvt053zuWuKD29h5tZnpkVmdmI8PWg7CzQGjd2720+aBypVMdNLUOCxRGr\npeJhg7dXRznncl2HPb0lvT3ddDP7S8+Hk9vq9jZjdmgfjGQjhhRyxLjhkRu+N9Q0sWd/i3fYc87l\nvChDg1yX9HwIcAKwFHhnViLKYTWN+4FDBx5MtXBqGQ+u2EJr3DrsV9HVe3g751xvi1IldX7S4yxg\nHtAz9yPtZ9obFiTV8dPK2bO/hVe3ddzUs7qqjqL8PGaPHd4jMTrnXLZ0pZV1M3BUTwfSHyRGqm3v\nstqExCixUcaVWllVx5Hjh1NU4A3ezrncFqUN478BC1/mAfMJenwPOomRajsqYUwqG8q4EcUsWV/L\nJSdNa3c5M2NVVR3nHjOhJ8N0zrmsiNKGsSTpeQtwp5k9l6V4clrUEoYkKqeVd3jL1k01e6nf5w3e\nzrn+IUrCuA/YZ2atAJLyJZWYWVN2Q8s9tY0xhhbmM7Qov8NlK6eW8cjLW9myey8TRg1Nu8yqLd7D\n2znXf0Tq6Q0kn/GGAn/OTji5raNe3skqp4YDEWZox1hVVUdBnjh8nDd4O+dyX5SEMcTM9iRehM9L\nshdS7qptjJ4wjho/nJKifJZmqJZaWVXH4eOGM6Sw4xKLc871tSgJo1HScYkXkhYCe6NsXNLZkl6T\ntFbS9Wnmj5T0B0kvSVotaVHUdftCTVNzh30wEgry81gwZVS7Pb7NEkOae/uFc65/iJIwrgXulfSs\npL8CdwNXdbSSpHyCkW7PAeYAF0uak7LYlcArZnYscDrwA0lFEdftdTWN+ykvaX8cqVQLp5bz6rZ6\n9qQZiHCCAkNTAAAYYUlEQVRL3T5qGmPefuGc6zc6bPQ2s8WSjgSOCCe9ZmbNEbZ9ArDWzNYBSLoL\nuAB4JXnzwPBwJNxhQA3BlVhvi7Bur6ttjF7CgKDhO26wfGMtp82uOGjeqrCH91xPGM65fqLDEoak\nK4FSM1tlZquAYZI+F2HbE4FNSa83h9OS3UjQCXALsBK4JrwHR5R1E/FdJmmJpCXV1dURwuqa/S2t\n7NnfknHgwVQLpowir52BCFdV1ZGfJ+aM9yop51z/EKVK6jNm1jZWt5nVAp/pof2/B1gBTCDoEHij\npE6dQc3sZjOrNLPKioqKjlfoot1NQaGqMyWM4UMKOfKwESxNMxDhqqo6ZlUM8wZv51y/ESVh5Cff\nPClsX4hy1qwCJie9nhROS7YIeMACa4G3gCMjrturEp32ol4llVA5rYzlG3fT0hpvm2ZmrKyqZ643\neDvn+pEoCeMx4G5JZ0o6E7gznNaRxcBsSdMlFQEXAQ+lLLMROBNA0jiCdpJ1EdftVbVdThjlNMVa\nWbO1oW3ajob97Nyz3xu8nXP9SpSe3l8GLgOuCF//CfhFRyuZWYukq4DHgXzgFjNbLemz4fybgG8D\nt0paCQj4spntBEi3bqfeWQ+riTiOVKrKcCDCJRtqOHpSkCBW+ZDmzrl+KMpVUnHgpvCBpMnAF4Eb\nIqz7KPBoyrSbkp5vAd4ddd2+VBtxHKlUE0YNZcLIISzZUMuiU6YDQYc9CW/wds71K5HG1JZUIelz\nkp4FngbGZTWqHLQrTBijOtEPIyExEKFZMOjvqqp6ZowppbQ4SgHPOedyQ7sJQ9JwSZ+Q9DjwIjAT\nmG5mM83sn3stwhxR2xhjxJACCvM7f9+KymllbK/fz+baoIP8qqo6b79wzvU7mX7i7iBIFF8F/mpm\nJunC3gkr99Q0NXe6/SIh+YZKQwrz2Va/z9svnHP9Tqafy18BioH/Ab4iaWbvhJSbahtjneqDkezI\nw0YwrLiAJRtq2oY0nzvBE4Zzrn9pN2GY2Y/M7ESCITkAfg9MkPRlSYf3SnQ5pKYx1qle3sny88SC\nKaNYsr6W1W1DgniDt3Ouf+mwQt7M1pnZ98zsaKASGEEOXb3UW2o7cS+MdCqnlvPa9gaef3MX00aX\nMGJI5xvPnXOuL3WqBTccT+pfzWxWtgLKRWYWlDC6kzCmlWEGz7+5y9svnHP9Uucv+RmE9ja3sr8l\n3uU2DID5k0eRnxeMsOIJwznXH3nCiGDXnrCXdxfbMABKiwvaOur5JbXOuf7IE0YEteGwIN0pYUBQ\nLQUwd4I3eDvn+p92+2GE4ztZe/PN7JisRJSDDoxU272G6s+dPou3z65gVDdKKs4511cyddw7L/x7\nZfj3N+Hfj2YvnNzUVsLo5om+YngxZxw5tidCcs65XtduwjCzDQCSzjKzBUmzrpe0DLg+28HliprG\n4OZJo0uL+zgS55zrO1HaMCTplKQXJ0dcb8CobYyRnyeGD/HBAp1zg1eUM+CngFskJS7t2Q18Mnsh\n5Z6aphhlJYXk5anjhZ1zboCKcj+MpcCxiYRhZnVZjyrH1DbGut1+4Zxz/V2HVUuSxkn6FXCXmdVJ\nmiPpU70QW87Y1Y2BB51zbqCI0hZxK8GtUieEr18Hrs1WQLmothsDDzrn3EARJWGMMbN7gDgE9+oG\nWrMaVY6pbfIShnPORUkYjZJGE3bik3QiMGjaMeJxo7apudud9pxzrr+LcpXUF4CHgJmSngMqgA9m\nNaoc0rCvhda4Ue59MJxzg1yUhLEaeAdwBCDgNQZRP4yapp4ZFsQ55/q7KCf+F8ysxcxWh/fDaAZe\nyHZguSIxjpRfVuucG+wyDT54GDARGCppAUHpAoI77pX0Qmw5obZt4EFPGM65wS1TldR7gEuBScAP\nk6Y3AP+SxZhyipcwnHMukGnwwduA2yR9wMzu78WYcsqBNgxPGM65wS3K0CD3SzoXmAsMSZr+rWwG\nlitqG2MUFeRRUpTf16E451yfijI0yE3Ah4GrCdoxPghMzXJcOaOmMcbo0iIkH3jQOTe4RblK6mQz\nuwSoNbNvAicBh2c3rNxR2+QDDzrnHERLGHvDv02SJgDNwPjshZRbahpj3n7hnHNESxgPSxoF3AAs\nA9YDd2YzqFxS29Ts40g55xzRGr2/HT69X9LDwJDBdE+MmsYY5SXey9s55zJ13Ht/hnmY2QPZCSl3\nNLfGqdvrJQznnIPMJYzzw79jgZOB/wtfnwE8D3SYMCSdDfwYyAd+aWb/kTL/OuCjSbEcBVSYWY2k\nfwI+TTBK7kpgkZnti/KmesrupmbA+2A45xxkaMMws0VmtggoBOaY2QfM7AME/TE6rKORlA/8FDgH\nmANcLGlOyj5uMLP5ZjYf+ArwTJgsJgKfByrNbB5Bwrmoa2+x62qbvJe3c84lRGn0nmxmW5Nebwem\nRFjvBGCtma0zsxhwF3BBhuUv5uDG9AKCcawKCMau2hJhnz0qMSzIaC9hOOdcpITxpKTHJV0q6VLg\nEeDPEdabCGxKer05nHYISSXA2cD9AGZWBfwXsBHYCtSZ2RPtrHuZpCWSllRXV0cIK7rEwIPehuGc\ncxEShpldBfwcODZ83GxmV/dwHOcDz5lZDYCkMoLSyHSCe4mXSvpYO/HdbGaVZlZZUVHRo0H5OFLO\nOXdAlBsoJa6I6uxVUVXA5KTXk8Jp6VzEwdVR7wLeMrNqAEkPEDS8397JGLolUcIY5ZfVOudc+yUM\nSX8N/zZIqk96NEiqj7DtxcBsSdMlFREkhYfS7GckwR39HkyavBE4UVKJgkGczgTWRH9bPaOmsZlh\nxQUUF/jAg845l2l481PDv8O7smEza5F0FfA4wVVOt5jZakmfDeffFC56IfCEmTUmrft3SfcR9Cxv\nAZYDN3clju6obYpR5rdmdc45IHPHvfJMKybaGzpY5lHg0ZRpN6W8vhW4Nc26Xwe+3tE+smlXY4xy\nv6TWOeeAzG0YSwk6zaUb19uAGVmJKIfUNsYYM8wThnPOQeYqqem9GUguqmmMMXvcsL4OwznnckKk\nq6TCy1xnc/Ad9/6SraByRW2TV0k551xChwlD0qeBawgui10BnAi8ALwzu6H1rX3NrTTFWr3TnnPO\nhaL09L4GOB7YYGZnAAuA3VmNKgfUeqc955w7SJSEsS8xSqykYjN7FTgiu2H1vcQ4Uj7woHPOBaK0\nYWwO77j3e+BPkmqBDdkNq+/VNvrQ5s45lyzKHfcuDJ9+Q9JTwEjgsaxGlQN2Ne4HoNw77jnnHJC5\n496jwG+B35vZHgAze6a3AutriXGkykuL+zgS55zLDZnaMH4OnAu8JekeSReGY0INCjVNzUgwcqiX\nMJxzDjLfce9BM7sYmEpwn4pLgI2S/lfSWb0VYF+pbYwxamgh+XnpOro759zgE+V+GE1mdnfYlvFu\nYD6DoA2jpinmfTCccy5JhwlD0jhJV0t6juBKqceB47IeWR+r9YEHnXPuIJkavT9DcJ/tIwiqpK4z\ns+d7K7C+VtMYY3J5SV+H4ZxzOSPTZbUnAf8OPGlm8V6KJ2fUNsU4dtKovg7DOedyRqZG70+a2Z+S\nk4Wkb/RKVH3MzKhp9DYM55xLFmVokGTvy0oUOWbP/haaW43RnjCcc65NZxPGoLjGNDEsiJcwnHPu\ngM4mjIVZiSLH1LSNVOud9pxzLiHKZbXflzRCUiHB4IPVkj7WC7H1mVofqdY55w4RpYTxbjOrB84D\n1gOzgOuyGVRfq2n0e2E451yqKAkjcentucC9ZlaXxXhyQuLmSd6G4ZxzB0S5H8bDkl4F9gJXSKoA\n9mU3rL5V0xijMF8ML450y3PnnBsUoowldT1wMlBpZs1AI3BBtgPrSzWNMcpKipAGxUVhzjkXSZRG\n7w8CzWbWKumrwO3AhKxH1odqGmPefuGccymitGH8m5k1SDoVeBfwK+Bn2Q2rb9U2xfwKKeecSxEl\nYbSGf88FbjazR4ABfTb1EoZzzh0qSsKokvRz4MPAo5KKI67Xb9U2NVPmnfacc+4gUU78HyK4B8Z7\nzGw3UM4A7ofRGjd2N/m9MJxzLlWkO+4BbwLvkXQVMNbMnsh6ZH2kfm8zcfM+GM45lyrKVVLXAHcA\nY8PH7ZKuznZgfeXAOFKeMJxzLlmUnmmfAt5mZo0Akv4TeAH472wG1ld8WBDnnEsvShuGOHClFOHz\nSD3aJJ0t6TVJayVdn2b+dZJWhI9VklollYfzRkm6T9KrktZIOinKPrurxgcedM65tKKUMP4X+Luk\n34Wv/4GgL0ZGkvKBnwJnAZuBxZIeMrNXEsuY2Q3ADeHy5wP/ZGY14ewfA4+Z2T9KKgJ65QbbtV7C\ncM65tDpMGGb2Q0lPA6eGkxaZ2fII2z4BWGtm6wAk3UUwpMgr7Sx/MXBnuOxI4O3ApWEMMSAWYZ/d\nlmjD8BKGc84dLGPCCEsJq83sSGBZJ7c9EdiU9Hoz8LZ29lMCnA1cFU6aDlQD/yvpWGApcE2iHSWb\nahtjDC3MZ2hRfrZ35Zxz/UrGNgwzawVekzQly3GcDzyXVB1VABwH/MzMFhAMeHhIGwiApMskLZG0\npLq6utuB1DQ2e3WUc86lEaUNowxYLelFghM3AGb2vg7WqwImJ72eFE5L5yLC6qjQZmCzmf09fH0f\n7SQMM7sZuBmgsrLSOoipQ7VNMe/l7ZxzaURJGP/WxW0vBmZLmk6QKC4CPpK6UNhe8Q6g7bavZrZN\n0iZJR5jZa8CZtN/20aOCcaSKe2NXzjnXr7SbMCTNAsaZ2TMp008Ftna0YTNrCXuGPw7kA7eY2WpJ\nnw3n3xQueiHwRJr2iauBO8IrpNYBiyK+p26paYwxbXSvXJDlnHP9SqYSxo+Ar6SZXhfOO7+jjZvZ\no8CjKdNuSnl9K3BrmnVXAJUd7aOn1TbGfFgQ55xLI1Oj9zgzW5k6MZw2LWsR9aFYS5yG/S0+8KBz\nzqWRKWGMyjBvaE8Hkgt2J/pgeAnDOecOkSlhLJH0mdSJkj5N0C9iwPGBB51zrn2Z2jCuBX4n6aMc\nSBCVBHfbuzDbgfUFH0fKOefa127CMLPtwMmSzgDmhZMfMbP/65XI+kBtYzPgJQznnEsnylhSTwFP\n9UIsfc6rpJxzrn0D+t7cnVWzJ0gYo0q8p7dzzqXyhJGktinGiCEFFOb7YXHOuVR+ZkwSDAvi1VHO\nOZeOJ4wkwcCDnjCccy4dTxhJahpj3svbOefa4QkjiY8j5Zxz7fOEkaSmKcZoTxjOOZeWJ4zQ3lgr\n+5rjXsJwzrl2eMIItXXa8zYM55xLyxNGKNFpz0sYzjmXnieM0IFhQbyXt3POpeMJI1TrI9U651xG\nnjBCiaHNvae3c86l5wkjVNsUIz9PjBjiVVLOOZeOJ4xQTWOMspJC8vLU16E451xO8oQRqm2KefuF\nc85l4AkjVOPDgjjnXEaeMEI+8KBzzmXmCSNU09jsJQznnMvAEwZgZtQ2xbzTnnPOZeAJA6jf10Jr\n3LzR2znnMvCEwYFe3t5pzznn2ucJg+RxpDxhOOdcezxh4CUM55yLwhMGB8aR8jYM55xrnycMfOBB\n55yLwhMGQRtGUUEeJUX5fR2Kc87lrKwmDElnS3pN0lpJ16eZf52kFeFjlaRWSeVJ8/MlLZf0cDbj\nrA17eUs+8KBzzrUnawlDUj7wU+AcYA5wsaQ5ycuY2Q1mNt/M5gNfAZ4xs5qkRa4B1mQrxgTv5e2c\ncx3LZgnjBGCtma0zsxhwF3BBhuUvBu5MvJA0CTgX+GUWYwSCkWpHe8JwzrmMspkwJgKbkl5vDqcd\nQlIJcDZwf9LkHwFfAuKZdiLpMklLJC2prq7uUqC1PlKtc851KFcavc8HnktUR0k6D9hhZks7WtHM\nbjazSjOrrKio6NLOa5pilJf4OFLOOZdJNhNGFTA56fWkcFo6F5FUHQWcArxP0nqCqqx3Sro9G0Ga\nGWccMZb5U0ZlY/POOTdgyMyys2GpAHgdOJMgUSwGPmJmq1OWGwm8BUw2s8Y02zkd+GczO6+jfVZW\nVtqSJUt6IHrnnBscJC01s8ooyxZkKwgza5F0FfA4kA/cYmarJX02nH9TuOiFwBPpkoVzzrnckbUS\nRl/wEoZzznVOZ0oYudLo7ZxzLsd5wnDOOReJJwznnHOReMJwzjkXiScM55xzkXjCcM45F8mAuqxW\nUjWwARgD7OzjcHKBH4eAH4eAH4eAH4dA4jhMNbNI4yoNqISRIGlJ1OuKBzI/DgE/DgE/DgE/DoGu\nHAevknLOOReJJwznnHORDNSEcXNfB5Aj/DgE/DgE/DgE/DgEOn0cBmQbhnPOuZ43UEsYzjnnepgn\nDOecc5EMqIQh6WxJr0laK+n6vo6nr0haL2mlpBWSBtV475JukbRD0qqkaeWS/iTpjfBvWV/G2Bva\nOQ7fkFQVfi9WSHpvX8bYGyRNlvSUpFckrZZ0TTh9UH0nMhyHTn0nBkwbhqR8gjv8nQVsJrjD38Vm\n9kqfBtYHwlvbVprZoOucJOntwB7g12Y2L5z2faDGzP4j/CFRZmZf7ss4s62d4/ANYI+Z/Vdfxtab\nJI0HxpvZMknDgaXAPwCXMoi+ExmOw4foxHdiIJUwTgDWmtk6M4sR3Av8gj6OyfUyM/sLUJMy+QLg\ntvD5bQT/KANaO8dh0DGzrWa2LHzeAKwBJjLIvhMZjkOnDKSEMRHYlPR6M104IAOEAX+WtFTSZX0d\nTA4YZ2Zbw+fbgHF9GUwfu1rSy2GV1YCuhkklaRqwAPg7g/g7kXIcoBPfiYGUMNwBp5rZfOAc4Mqw\nesIBFtTBDox62M77GTADmA9sBX7Qt+H0HknDgPuBa82sPnneYPpOpDkOnfpODKSEUQVMTno9KZw2\n6JhZVfh3B/A7guq6wWx7WIebqMvd0cfx9Akz225mrWYWB37BIPleSCokOEneYWYPhJMH3Xci3XHo\n7HdiICWMxcBsSdMlFQEXAQ/1cUy9TlJp2KiFpFLg3cCqzGsNeA8BnwiffwJ4sA9j6TOJE2ToQgbB\n90KSgF8Ba8zsh0mzBtV3or3j0NnvxIC5SgogvCTsR0A+cIuZfbePQ+p1kmYQlCoACoDfDqbjIOlO\n4HSCoZu3A18Hfg/cA0whGP7+Q2Y2oBuE2zkOpxNUPRiwHrg8qR5/QJJ0KvAssBKIh5P/haD+ftB8\nJzIch4vpxHdiQCUM55xz2TOQqqScc85lkScM55xzkXjCcM45F4knDOecc5F4wnDOOReJJwzXr4Qj\nbr4nZdq1kn7WwXp7shxXhaS/S1ou6bSUeU9LqgyfTw9HSH1Pmm3cEI4kekMXYzhd0sNJr78j6TFJ\nxWEMS5LmVUp6Omk9k3R+0vyHJZ3elTjcwOUJw/U3dxJ0ykx2UTi9L50JrDSzBWb2bLoFJE0CHgO+\naGaPp1nkMuAYM7suyg4lFWSY91XgFOBCM9sfTh4r6Zx2VtkM/GuU/brByxOG62/uA84Ne/MnBlKb\nADwraZikJyUtU3A/kENGK07zK/xGSZeGzxdKeiYctPHxlF6wieWnSfq/cLC2JyVNkTQf+D5wQXhP\ngaFp4h4PPAH8q5kdMgKBpIeAYcBSSR9Ot59wuVsl3STp7+E+DyHpiwTjiJ1vZnuTZt1A+0nhJaBO\n0lntzHfOE4brX8LeuC8SnBAhKF3cEw4gt4/gF/VxwBnAD8IhEToUjrPz38A/mtlC4BYgXQ/5/wZu\nM7NjgDuAn5jZCuBrwN1mNj/lJJ1wG3Cjmd3Xzvt6H7A3XP/udPtJWnwScLKZfSHNpk4BPgucY2ap\n1XAvADFJZ6SLIXy/X21nnnOeMFy/lFwtlVwdJeB7kl4G/kwwvH3UYauPAOYBf5K0guDEOSnNcicB\nvw2f/wY4NeL2/wx8TFJJxOUz7edeM2ttZ721BMehvZLCd2gnKYT30EgMI+HcITxhuP7oQeBMSccB\nJWa2NJz+UaACWBgO774dGJKybgsHf+8T8wWsDn/hzzezo83s3T0Y8/cJBsi8N1PbQ0SNGeZtB94L\n/ChdScLM/g8YCpzYzvpeynDt8oTh+p2wquUpgmqj5MbukcAOM2sOT5ZT06y+AZgTXjk0iqCxGuA1\noELSSRBUUUmam2b95zlQuvkowYBuUV0L1AO/ilBV1uX9mNnrwPuB28P2lVTfAb7UzrpPAGXAMVH3\n5wYPTxiuv7oTOJaDE8YdQKWklcAlwKupK5nZJoJRSleFf5eH02PAPwL/KeklYAVwcpr9Xg0sCqu9\nPg5cEzXgsJ3lEwQN4GkbrHtiP+G+FgOLgIckzUyZ9yhQnWH173LwvWWcA3y0WueccxF5CcM551wk\nnjCcc85F4gnDOedcJJ4wnHPOReIJwznnXCSeMJxzzkXiCcM551wk/x855O1t7LnoqgAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bfe0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Neighbours vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that increasing number of neighbours improves accuracy. However, we need to be wary of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "treeopt = tree_cv.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.849\n",
      "{'min_samples_leaf': 1, 'max_features': 8, 'max_depth': 3, 'criterion': 'entropy'}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%tree_cv.best_score_)\n",
    "print(tree_cv.best_params_)\n",
    "print(tree_cv.best_estimator_)\n",
    "models.append(treeopt)\n",
    "modelname.append('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision tree, we should set min sample leaves to 5, have a maximum of 8 features, a max depth of 3, and using the gini criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8467504861939702, 0.84682529430002162, 0.84866566765941054, 0.85042864927329265, 0.84966342224184732, 0.84299223029152837, 0.84261102603369076, 0.84184192354306209]\n"
     ]
    }
   ],
   "source": [
    "#Now constructing a graph for this\n",
    "tree_range = range(2, 10)\n",
    "\n",
    "# list of scores from t_range\n",
    "t_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in tree_range:\n",
    "    # 2. run Decision tree with different value for depth of tree\n",
    "    tree = DecisionTreeClassifier(max_depth = k, criterion='gini', max_features = 8, max_leaf_nodes = None )\n",
    "    # 3. obtain cross_val_score for Decision tree with depth of k\n",
    "    scores = cross_val_score(tree, final_train, y_train, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for decision tree to t_scores list\n",
    "    t_scores.append(scores.mean())\n",
    "print(t_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x115618b38>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bfeba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the value of Depth for Decision Tree(x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of Depth for Decision Tree')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Depth vs Cross-validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(5,15),\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_split\": range(2,5),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              }\n",
    "\n",
    "# Instantiate a Extremely Random Forest classifier: randext\n",
    "randFor = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randFor_cv\n",
    "randFor_cv = RandomizedSearchCV(randFor,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optrand = randFor_cv.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.853\n",
      "{'n_estimators': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 8, 'max_depth': 3}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randFor_cv.best_score_)\n",
    "print(randFor_cv.best_params_)\n",
    "print(randFor_cv.best_estimator_)\n",
    "models.append(optrand)\n",
    "modelname.append('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:\n",
    "\n",
    "n_estimators: 10\n",
    "\n",
    "maximum features: 8\n",
    "\n",
    "min_samples_split: 2\n",
    "\n",
    "min_samples_leaf: 8\n",
    "\n",
    "No maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(5,15),\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": range(1, 9),\n",
    "              \"min_samples_split\": range(2,5),\n",
    "              \"min_samples_leaf\": range(1, 9),\n",
    "              }\n",
    "\n",
    "# Instantiate a Extremely Random Forest classifier: randext\n",
    "randExt = ExtraTreesClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randext_cv\n",
    "randExt_cv = RandomizedSearchCV(randExt,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optext = randExt_cv.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.850\n",
      "{'n_estimators': 11, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 5, 'max_depth': None}\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features=5, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=6, min_samples_split=3,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randExt_cv.best_score_)\n",
    "print(randExt_cv.best_params_)\n",
    "print(randExt_cv.best_estimator_)\n",
    "models.append(optext)\n",
    "modelname.append('Extremely Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 11, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 5, 'max_depth': None} tells us the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"n_estimators\": range(330,400,10),\n",
    "              \"learning_rate\": range(1,5),\n",
    "              }\n",
    "\n",
    "# Instantiate a Adaptie boosting classifier: tree\n",
    "randAda = AdaBoostClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randada_cv\n",
    "randAda_cv = RandomizedSearchCV(randAda,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optada = randAda_cv.fit(final_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.852\n",
      "{'n_estimators': 350, 'learning_rate': 1}\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=350, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randAda_cv.best_score_)\n",
    "print(randAda_cv.best_params_)\n",
    "print(randAda_cv.best_estimator_)\n",
    "models.append(optada)\n",
    "modelname.append('Adaptive Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"loss\": [\"deviance\", \"exponential\"],\n",
    "              \"n_estimators\": range(250,550,50),\n",
    "              \"learning_rate\": [0.1],\n",
    "              \"min_samples_split\" : [2,4],\n",
    "              \"min_samples_leaf\" : range(1,3)\n",
    "              }\n",
    "\n",
    "# Instantiate a GB boosting classifier: randGB\n",
    "randGB = GradientBoostingClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: randGB_cv\n",
    "randGB_cv = RandomizedSearchCV(randGB,param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "\n",
    "#Fitting the model and testing out random hyperparameters. This saves on computation time\n",
    "optgb = randGB_cv.fit(final_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model is 0.856\n",
      "{'n_estimators': 250, 'min_samples_split': 4, 'min_samples_leaf': 2, 'loss': 'exponential', 'learning_rate': 0.1}\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=2, min_samples_split=4,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print('Accuracy of this model is %.3f'%randGB_cv.best_score_)\n",
    "print(randGB_cv.best_params_)\n",
    "print(randGB_cv.best_estimator_)\n",
    "models.append(optgb)\n",
    "modelname.append('Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same interpretation as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have finalised tuning our hyperparameters and therefore we can retrain our models to see final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "LogReg = LogisticRegression()\n",
    "optlog = LogReg.fit(final_train,y_train)\n",
    "models.append(optlog)\n",
    "modelname.append('Logit')\n",
    "\n",
    "#Naive Bayes\n",
    "NaiveB = GaussianNB()\n",
    "optnb = NaiveB.fit(final_train,y_train)\n",
    "models.append(optnb)\n",
    "modelname.append('Naive Bayes')\n",
    "\n",
    "#Linear Discriminant analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "optlda = LDA.fit(final_train,y_train)\n",
    "models.append(optlda)\n",
    "modelname.append('LDA')\n",
    "\n",
    "#Quadratic Discriminant analysis\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "optqda = QDA.fit(final_train,y_train)\n",
    "models.append(optqda)\n",
    "modelname.append('QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates us a table for results with hyperparameter optimised models\n",
    "def getResultTable2(rows, modelsUsed):\n",
    "    columns=['Accuracy for No', 'Accuracy for Yes', 'Overall Accuracy']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "    predictions = []\n",
    "    for clf in modelsUsed:\n",
    "        pred = clf.predict(final_test)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        matrix = confusion_matrix(y_test, pred)\n",
    "        results.iloc[row,0] = (matrix[0][0]/(matrix[0][0]+matrix[1][0]))\n",
    "        results.iloc[row,1] = (matrix[1][1]/(matrix[0][1]+matrix[1][1]))\n",
    "        results.iloc[row,2] = (accuracy_score(y_test, pred))\n",
    "        \n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Random Forest</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaptive Boosting</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy for Yes  Accuracy for No  Overall Accuracy\n",
       "KNN                                 0.833              NaN             0.833\n",
       "Decision Tree                       0.846            0.686             0.842\n",
       "Random Forest                       0.859            0.676             0.850\n",
       "Extremely Random Forest             0.861            0.649             0.850\n",
       "Adaptive Boosting                   0.876            0.594             0.850\n",
       "Gradient Boosting                   0.873            0.647             0.856\n",
       "Logit                               0.833              NaN             0.833\n",
       "Naive Bayes                         0.834            0.224             0.830\n",
       "LDA                                 0.868            0.606             0.849\n",
       "QDA                                 0.902            0.391             0.782"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Warning, this takes a while to run!\n",
    "getResultTable2(modelname, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now combine our models in order to create even better models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have predictions from our models and we can take a majority vote to predict each observation. Here, we use a majority vote. Here, we assign each model as having a vote that is of equal importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemmodels = []\n",
    "ensempredictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we take the 3 and 4 best models to create our model with hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem = VotingClassifier(estimators=[('Adaptive', optada), ('DecisionTree', treeopt), ('GradientBoost', optgb)], voting='hard')\n",
    "ensemmodels.append('Adaboost DecisionTree GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem1 = ensem.fit(final_train,y_train)\n",
    "ensempred1 = ensem1.predict(final_test)\n",
    "ensempredictions.append(ensempred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem2 = VotingClassifier(estimators=[('Adaptive', optada), ('DecisionTree', treeopt), ('GradientBoost', optgb), ('LDA', optlda)], voting='hard')\n",
    "ensemmodels.append('Adaboost DecisionTree GradientBoost LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensem2 = ensem2.fit(final_train,y_train)\n",
    "ensempred2 = ensem2.predict(final_test)\n",
    "ensempredictions.append(ensempred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy for Yes</th>\n",
       "      <th>Accuracy for No</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adaboost DecisionTree GradientBoost</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost DecisionTree GradientBoost LDA</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Accuracy for Yes  Accuracy for No  \\\n",
       "Adaboost DecisionTree GradientBoost                 0.871            0.655   \n",
       "Adaboost DecisionTree GradientBoost LDA             0.860            0.694   \n",
       "\n",
       "                                         Overall Accuracy  \n",
       "Adaboost DecisionTree GradientBoost                 0.856  \n",
       "Adaboost DecisionTree GradientBoost LDA             0.852  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(ensemmodels,ensempredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the best ensemble model and then try soft voting. Here, each base model gets a different weight\n",
    "in their vote. We can use gridsearch CV to find optimal level of weighting for each model.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalensem = VotingClassifier(estimators=[('LDA', optada), ('ExtraTrees', Extratree), ('GradientBoost', GradBoost)], voting='soft', weights = [1,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LDA', RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distribution...         presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[1, 1, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalensem.fit(final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalresults = finalensem.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855450781969\n"
     ]
    }
   ],
   "source": [
    "#Final results\n",
    "print(accuracy_score(y_test, finalresults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like hardvoting with Adaptive boosting, decision trees, and gradient boosting performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train += 0.001\n",
    "final_test += 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to scale the dataset to help the neural net learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(final_train)\n",
    "x_train_scale = scaler.transform(final_train)\n",
    "x_test_scale = scaler.transform(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    #Construct a neural network object:\n",
    "    model = Sequential()\n",
    "    #Input dimension for input layer MUST match the number of predictors in our dataset. Output dimension tells us \n",
    "    #how many edges going into next layer (can be any number from 1 to number of vertices in next layer). \n",
    "    #Kernel_init tells us what initial weightings to set the weights when training it. Relu is activation function:\n",
    "    model.add(Dense(input_dim=50, output_dim = 1000, kernel_initializer='normal', activation='relu'))\n",
    "    #Here we created a layer with 10000 vertices and the same parameters as before:\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'sigmoid'))\n",
    "    # Compile model from this. Keep this loss function whilst rmsprop is a better optimizer:\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13044/13044 [==============================] - 13s - loss: 0.3734 - acc: 0.8434    \n",
      "Epoch 2/25\n",
      "13044/13044 [==============================] - 13s - loss: 0.3463 - acc: 0.8513    \n",
      "Epoch 3/25\n",
      "13044/13044 [==============================] - 13s - loss: 0.3384 - acc: 0.8527    \n",
      "Epoch 4/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.3357 - acc: 0.8507    \n",
      "Epoch 5/25\n",
      "13044/13044 [==============================] - 9s - loss: 0.3192 - acc: 0.8587     \n",
      "Epoch 6/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.3108 - acc: 0.8615    \n",
      "Epoch 7/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.2985 - acc: 0.8679    \n",
      "Epoch 8/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.2880 - acc: 0.8743    \n",
      "Epoch 9/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.2774 - acc: 0.8793    \n",
      "Epoch 10/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.2675 - acc: 0.8865    \n",
      "Epoch 11/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.2435 - acc: 0.9000    \n",
      "Epoch 12/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.2301 - acc: 0.9065    \n",
      "Epoch 13/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.2162 - acc: 0.9098    \n",
      "Epoch 14/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.1952 - acc: 0.9221    \n",
      "Epoch 15/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1795 - acc: 0.9314    \n",
      "Epoch 16/25\n",
      "13044/13044 [==============================] - 10s - loss: 0.1678 - acc: 0.9342    \n",
      "Epoch 17/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1507 - acc: 0.9437    \n",
      "Epoch 18/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1392 - acc: 0.9486    \n",
      "Epoch 19/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1437 - acc: 0.9495    \n",
      "Epoch 20/25\n",
      "13044/13044 [==============================] - 12s - loss: 0.1374 - acc: 0.9532    \n",
      "Epoch 21/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1476 - acc: 0.9534    \n",
      "Epoch 22/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1963 - acc: 0.9506    - ETA: 2s\n",
      "Epoch 23/25\n",
      "13044/13044 [==============================] - 12s - loss: 0.1885 - acc: 0.9541    \n",
      "Epoch 24/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.1991 - acc: 0.9571    \n",
      "Epoch 25/25\n",
      "13044/13044 [==============================] - 11s - loss: 0.2243 - acc: 0.9556    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12030ae48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(x_train_scale, y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8696/8696 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6489517377225105, 0.84073137080000426]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
